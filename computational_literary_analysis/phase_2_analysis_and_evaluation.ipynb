{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Analysis & evaluation\n",
    "\n",
    "In part one of the project I constructed a data processing pipeline that took in the raw text of 3 books, and produced 'ready-to-use' outputs saved to a database:\n",
    "\n",
    "![Main pipeline components](pipeline.png)\n",
    "\n",
    "The objective now is to use this dataset to:\n",
    "\n",
    "__1. Identify key characters in novels (information extraction)__\n",
    "\n",
    "And then  demonstrate how we could use the information extracted (about the books and their characters) to: \n",
    "\n",
    "__2. Present potentially useful contextual and quantitative information to aid the reading experience (visualization)__\n",
    "\n",
    "The outputs, if successful, should potentially _assist_ a human literary analyst with contextual information; as well as providing a more quantitative perspective to supplement traditional qualitative methods.\n",
    "\n",
    "The three initial novels selected for the project were obtained (with permission) from Project Gutenberg at the following locations:\n",
    "\n",
    "* __Great Expectations__: https://www.gutenberg.org/files/1400/1400-0.txt (Dickens, 1998)<br>\n",
    "* __Alice In Wonderland__: https://www.gutenberg.org/ebooks/19033.txt.utf-8 (Carroll, 2008)<br>\n",
    "* __Little Women__: https://www.gutenberg.org/ebooks/514.txt.utf-8 (Alcott, 1996)<br>\n",
    "\n",
    "I prepared a fourth book for the database which will be reserved for the evaluation phase - a test case we can use to assess whether the proposed methods can be applied to other books:\n",
    "\n",
    "* __Jane Eyre__: https://www.gutenberg.org/cache/epub/1260/pg1260.txt (Bronte, 1998)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard utilities\n",
    "import re\n",
    "import pprint\n",
    "import datetime\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLP tasks\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Storage\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Data checking\n",
    "import pywikibot\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas settings\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "# Pandas highlight columns gold\n",
    "def highlight_column(column):\n",
    "    '''Highlight specified columns in df - used as argument in df.style.apply() function'''\n",
    "    return ['background-color: gold' for item in column.values]\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "sns.set_theme()\n",
    "authors = ['dickens', 'carroll', 'alcott']\n",
    "all_authors = ['dickens', 'carroll', 'alcott', 'bronte']\n",
    "author_colors = {'dickens': '#ED230D', 'carroll': '#00A1FE', 'alcott': '#1EB100', 'bronte': '#FF1393'}\n",
    "author_colormaps = {'dickens': 'YlOrRd', 'carroll': 'GnBu', 'alcott': 'YlGn', 'bronte': 'PuRd'}\n",
    "\n",
    "# SQL settings\n",
    "%load_ext sql\n",
    "%sql sqlite:///book_store.db\n",
    "# Set the style to the old default as advised by\n",
    "# https://stackoverflow.com/questions/79153112/keyerror-default-when-attempting-to-create-a-table-using-magic-line-sql-in-j\n",
    "%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n",
    "\n",
    "engine = create_engine('sqlite:///book_store.db', echo=False)\n",
    "connection = engine.raw_connection()\n",
    "\n",
    "# Track time\n",
    "processing_start = datetime.datetime.now()\n",
    "\n",
    "# Pywikibot settings\n",
    "pywikibot.config.max_retries = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The datasets\n",
    "\n",
    "### 1.1 SQL data\n",
    "\n",
    "The current database, ```book_store.db```,  contains 5 tables (see _phase_1_data_preparation_and_eda.ipynb_ for more details):\n",
    "\n",
    "- The vocabularies used by each of the 4 authors\n",
    "- The book components is the main information source, where each book is broken down by author, chapter, paragraph, sentence, text, lemmas and sentence lengths\n",
    "- The chapter headings are, as implied, whatever the chapter headings are - even if simply \"Chapter IV.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///book_store.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>wikidata</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>chapter_headings</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>book_components</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dickens_vocab</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>carroll_vocab</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>alcott_vocab</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bronte_vocab</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('wikidata',),\n",
       " ('chapter_headings',),\n",
       " ('book_components',),\n",
       " ('dickens_vocab',),\n",
       " ('carroll_vocab',),\n",
       " ('alcott_vocab',),\n",
       " ('bronte_vocab',)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT name FROM sqlite_master WHERE type='table'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample of the first record from ```book_components``` - this is the data we will work with when performing information extraction and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///book_store.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chapter</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraph</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>My father’s family name being Pirrip, and my Christian name Philip, my infant tongue could make of both names nothing longer or more explicit than Pip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemmas</th>\n",
       "      <td>my;father;family;name;be;pirrip;and;my;christian;name;philip;my;infant;tongue;could;make;of;both;name;nothing;long;or;more;explicit;than;pip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                 0\n",
       "index                                                                                                                                                            0\n",
       "author                                                                                                                                                     dickens\n",
       "chapter                                                                                                                                                          0\n",
       "paragraph                                                                                                                                                        0\n",
       "sentence                                                                                                                                                         0\n",
       "text       My father’s family name being Pirrip, and my Christian name Philip, my infant tongue could make of both names nothing longer or more explicit than Pip.\n",
       "lemmas                my;father;family;name;be;pirrip;and;my;christian;name;philip;my;infant;tongue;could;make;of;both;name;nothing;long;or;more;explicit;than;pip"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = %sql SELECT * FROM book_components LIMIT 1\n",
    "result = result.DataFrame()\n",
    "result.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Incorporating Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don't have a 'source of truth' against which to compare the results we'll obtain I decided to use Wikidata as a proxy for this missing source of truth. Wikidata has a well-defined structure. My main objective is to extract the __characters__ (and their known __aliases__) from each book in order to use them as a comparative data source in the evaluation phase of this project, but I'll also bring in __genre__, __period__, __narrative location__ and __intended public__ which may be informative if they are available. Here is an example of the Wikidata structures relevant to my task:\n",
    "\n",
    "![Wikidata structure](little_women_structures.png)\n",
    "\n",
    "* __Items__ are entries in the knowledge base: each item has a unique identifier beginning with ```Q*```.\n",
    "* Each item has a __label__ (e.g. 'Little Women') and a __description__ (e.g. 'novel by Louisa May Alcott')\n",
    "* Claims represent links to the detail behind each item\n",
    "* Items may have __properties__ - properties are standardized: each property's unique identifier begins with ```P*``` (e.g. 'P674' is for characters and 'P136' is for genre)\n",
    "* Properties may refer to further items, for example the character _Jo March_ is also an item ('Q27902552') with its own label ('Jo March') and description ('fictional character from Louisa May Alcott's Little Women') which can be retrieved\n",
    "* __Aliases__ are also sometimes available, for example the character _Jo March_ is also known as _Josephine March_, _Aunt Dodo_, _Jo Bhaer_, _Josephine Bhaer_\n",
    "\n",
    "The Python library __pywikibot__ ([MediaWiki, 2022](https://www.mediawiki.org/w/index.php?title=Manual:Pywikibot&oldid=5039041)) enables us to navigate this structure and retrieve only the information we need for our purposes. I selected this library because:\n",
    "\n",
    "* It is recommended by Wikidata itself, which provides good documentation and tutorials such as [this one](https://www.wikidata.org/w/index.php?title=Wikidata:Pywikibot_-_Python_3_Tutorial/Data_Harvest&oldid=1056597057) (Wikidata, 2019) which gave me the starter code I needed to get going on formulating my own retrieval strategy (see below)\n",
    "* It is actively maintained - I've used release 6.6.3 December 2021, but there is already 6.6.4 available as of January 2022 ([The Pywikibot Team, 2022](https://pypi.org/project/pywikibot/#history)) - unlike for example Wikidata 0.7.0 which was last updated in 2020 ([Minhee, 2020](https://pypi.org/project/Wikidata/#history))\n",
    "* It abstracts away the need to understand complex [SPARQL](https://query.wikidata.org) retrieval queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing to retrieve Wikidata information\n",
    "\n",
    "I've broken the retrieval process down into 4 functions so that it is clear what is happening at each stage of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Component 1 ```make_wiki_page()``` - formulate a request for a page\n",
    "\n",
    "_Requirement notes:_\n",
    "\n",
    "1. Check that the book argument is given in the correct format (```str```)\n",
    "2. The language / family combination of 'en' and 'wikipedia' is important - but here I'm coding it into the function so there is no possibility for user error\n",
    "3. The book variable could be any string - at this stage there is no validation, we're just formulating our request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wiki_page(book):\n",
    "    '''Takes in the name of a book and returns a pywikibot.page.Page object \n",
    "    - does not require internet connection. Note that book is case-sensitive.'''\n",
    "    \n",
    "    if not isinstance(book, str):\n",
    "        return 'Argument \"book\" should be a string representing a valid book title'\n",
    "\n",
    "    site = pywikibot.Site('en', 'wikipedia')\n",
    "    page = pywikibot.Page(site, book)\n",
    "    return page     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Component 2 ```get_wiki_item()``` - request item from Wikidata\n",
    "\n",
    "_Requirement notes:_\n",
    "\n",
    "1. Check that page is given in the correct format (```pywikibot.page.Page```)\n",
    "2. An internet connection is required to retrieve the item, ```pywikibot.config.max_retries``` above is set to a maximum of 2 retries, BUT if there is still no response after that a ```TimeoutError``` may occur\n",
    "3. If the item exists it will be returned BUT if it does not exist a ```NoPageError``` may occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_item(page):\n",
    "    '''Takes in a pywikibot.page.Page object and returns a pywikibot.page.ItemPage object\n",
    "    if it exists - requires an internet connection'''\n",
    "    \n",
    "    if not isinstance(page, pywikibot.page.Page):\n",
    "        return 'Argument \"page\" should be a valid pywikibot.page.Page object'\n",
    "    \n",
    "    try:\n",
    "        item = pywikibot.ItemPage.fromPage(page)     \n",
    "        return item\n",
    "    \n",
    "    except Exception as err:\n",
    "        return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Component 3 ```compile_wiki_data()``` - obtain and package just the data points we need\n",
    "\n",
    "_Requirement notes:_\n",
    "\n",
    "1. Check that item is given in the correct format (```pywikibot.page.ItemPage```)\n",
    "2. An internet connection is required to retrieve the item claims to the properties of interest (these ```P*``` codes can easily be looked up on the Wikidata pages, simply by hovering over the property of interest's label as shown above)\n",
    "3. Not every property is necessarily available for every book\n",
    "3. Book details and property details should be assembled into a dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_wiki_data(item):\n",
    "    '''Takes in a pywikibot.page.ItemPage object and returns a dictionary containing labels, \n",
    "    descriptions, and properties of interest - requires an internet connection'''\n",
    "    \n",
    "    if not isinstance(item, pywikibot.page.ItemPage):\n",
    "        return 'Argument \"item\" should be a valid pywikibot.page.ItemPage object'\n",
    "    \n",
    "    try: \n",
    "        # Create a dictionary to store our results \n",
    "        book_wikidata = {}\n",
    "\n",
    "        properties_of_interest = {'characters': 'P674', \n",
    "                                  'main subject': 'P921',\n",
    "                                  'genre': 'P136', \n",
    "                                  'set in period': 'P2408',\n",
    "                                  'narrative location': 'P840',\n",
    "                                  'intended public': 'P2360'}\n",
    "\n",
    "        # Extract high-level data entries to our results dictionary\n",
    "        book_wikidata['item'] = item.id\n",
    "        book_wikidata['title'] = item.labels.get('en')\n",
    "        book_wikidata['description'] = item.descriptions.get('en')\n",
    "\n",
    "        # Claims contain the detail of each property we are interested in\n",
    "        item_dict = item.get()\n",
    "        clm_dict = item_dict.get('claims')\n",
    "        for key, value in properties_of_interest.items():\n",
    "            # Create an empty list for each property to hold results\n",
    "            book_wikidata[key] = []\n",
    "            # Get a list of claims\n",
    "            clm_list = clm_dict.get(value)\n",
    "            if clm_list != None:\n",
    "                for clm in clm_list:\n",
    "                    # Only if snaktype is 'value' is there actual data to return\n",
    "                    if clm.snaktype == 'value':\n",
    "                        clm_trgt = clm.getTarget()\n",
    "                        claim_detail = clm_trgt.get()\n",
    "                        # Append the labels for each item in the property, e.g. name of each character for characters\n",
    "                        if key == 'characters':\n",
    "                            book_wikidata[key].append((claim_detail.get('labels').get('en'), claim_detail.get('aliases').get('en')))\n",
    "                        else:\n",
    "                            book_wikidata[key].append((claim_detail.get('labels').get('en')))\n",
    "                        \n",
    "        return book_wikidata\n",
    "    except Exception as err:\n",
    "        return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Component 4 ```get_book_wikidata()``` - fetch and compile the data\n",
    "\n",
    "_Requirement notes:_\n",
    "\n",
    "1. Here we put the 3 functions so far together - each step either returns a valid instance for further processing or an error message which can shed light on the issue encountered\n",
    "2. A nested dict of data for each book is returned if no errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_wikidata(book):\n",
    "    '''Takes in the name of a book and returns a dict of properties of interest. Note that\n",
    "    book is case-sensitive.'''\n",
    "    page = make_wiki_page(book)\n",
    "    \n",
    "    # Check that page is valid\n",
    "    if isinstance(page, pywikibot.page.Page):\n",
    "        item = get_wiki_item(page)\n",
    "        # Check that item is valid\n",
    "        if isinstance(item, pywikibot.page.ItemPage):\n",
    "            book_wikidata = compile_wiki_data(item)\n",
    "            # Check that the dict is valid\n",
    "            if isinstance(book_wikidata, dict):\n",
    "                return book_wikidata\n",
    "            else:\n",
    "                err = f'''There was an issue with book_wikidata: {book_wikidata}'''\n",
    "                return err\n",
    "        else:\n",
    "            err = f'''There was an issue with item: {item}'''\n",
    "            return err\n",
    "    else:\n",
    "        err = f'''There was an issue with page: {page}'''\n",
    "        return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving WikiData information\n",
    "\n",
    "We are now ready to retrieve the data itself. Once we have it, we want to store it in the ```book_store``` database along with all the other project data so that it is available for future iterations without the need to keep connecting and retrieving the data each time - this step would then become part of the standard data processing pipeline along with all the other steps included in the preliminary part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dickens completed\n",
      "carroll completed\n",
      "alcott completed\n",
      "bronte completed\n"
     ]
    }
   ],
   "source": [
    "# Runs for a couple of minutes potentially (depending on connection speed - \n",
    "# alcott has the most characters and therefore runs the longest)\n",
    "wikidata_on_books = {}\n",
    "for author, book in [(\"dickens\", \"Great Expectations\"),\n",
    "                     (\"carroll\", \"Alice's Adventures in Wonderland\"),\n",
    "                     (\"alcott\", \"Little Women\"),\n",
    "                     (\"bronte\", \"Jane Eyre\")]:\n",
    "    wikidata = get_book_wikidata(book)\n",
    "    if isinstance(wikidata, dict): \n",
    "        wikidata_on_books[author] = get_book_wikidata(book)\n",
    "        print(f'''{author} completed''')\n",
    "    else:\n",
    "        print(f'''{author} encountered an issue: {wikidata}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>property</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dickens</td>\n",
       "      <td>item</td>\n",
       "      <td>Q219552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dickens</td>\n",
       "      <td>title</td>\n",
       "      <td>Great Expectations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dickens</td>\n",
       "      <td>description</td>\n",
       "      <td>1861 novel by Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dickens</td>\n",
       "      <td>characters</td>\n",
       "      <td>Pip^Philip Pirrip;Miss Havisham;Estella^Estella Havisham|Estella Drummle;Abel Magwitch;John Wemmick;Compeyson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dickens</td>\n",
       "      <td>main subject</td>\n",
       "      <td>orphan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    author      property  \\\n",
       "0  dickens          item   \n",
       "1  dickens         title   \n",
       "2  dickens   description   \n",
       "3  dickens    characters   \n",
       "4  dickens  main subject   \n",
       "\n",
       "                                                                                                            data  \n",
       "0                                                                                                        Q219552  \n",
       "1                                                                                             Great Expectations  \n",
       "2                                                                                  1861 novel by Charles Dickens  \n",
       "3  Pip^Philip Pirrip;Miss Havisham;Estella^Estella Havisham|Estella Drummle;Abel Magwitch;John Wemmick;Compeyson  \n",
       "4                                                                                                         orphan  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the data from a dict to an appropriate format for storing in our db\n",
    "wikidata = pd.json_normalize(wikidata_on_books).transpose().reset_index()\n",
    "wikidata.rename(columns={0:'data'}, inplace=True)\n",
    "wikidata[['author', 'property']] = wikidata['index'].str.split('.', expand=True)\n",
    "wikidata = wikidata[['author', 'property', 'data']]\n",
    "\n",
    "# We cannot store data type list in the database so transform any list / tuple combinations using\n",
    "# ';' to delimit characters and '^' to delimit character / alias combinations and '|' to delimit aliases\n",
    "wikidata_sql = wikidata.copy()\n",
    "wikidata_sql['data'] = wikidata_sql.apply(lambda row: \\\n",
    "                      ';'.join([char[0] + '^' + '|'.join(char[1]) if char[1] != None \\\n",
    "                      else char[0] for char in row['data']]) if isinstance(row['data'], list) and \\\n",
    "                                          row['property'] == 'characters' else row['data'], axis=1)\n",
    "wikidata_sql['data'] = wikidata_sql['data'].apply(lambda x: \\\n",
    "                      ';'.join(x) if isinstance(x, list)  else x)\n",
    "\n",
    "# Check the outputs\n",
    "wikidata_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'data' column for the characters property can be converted \n",
    "# from string to its original format with the following recipe if required:\n",
    "\n",
    "# wikidata_sql['data'] = wikidata_sql['data'].apply(lambda x: [(name, alias.split('|')) \\\n",
    "# if '|' in alias else (name, alias) for name, alias in [tuple(item.split('^'))  \n",
    "# if '^' in item else (item, 'None') for item in x.split(';')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then save to the database\n",
    "wikidata_sql.to_sql('wikidata', engine, schema=None, \n",
    "              if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///book_store.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>chapter_headings</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>book_components</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dickens_vocab</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>carroll_vocab</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>alcott_vocab</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bronte_vocab</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>wikidata</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('chapter_headings',),\n",
       " ('book_components',),\n",
       " ('dickens_vocab',),\n",
       " ('carroll_vocab',),\n",
       " ('alcott_vocab',),\n",
       " ('bronte_vocab',),\n",
       " ('wikidata',)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And check that it landed safely\n",
    "%sql SELECT name FROM sqlite_master WHERE type='table';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identifying key characters\n",
    "\n",
    "As a reminder we'll be looking at 3 methods:\n",
    "\n",
    "* NER using __NLTK__\n",
    "* NER using __spaCy__\n",
    "* Proper noun chunking using __NLTK__ parts-of-speech tagging\n",
    "\n",
    "The overall process I plan to follow is depicted below:\n",
    "\n",
    "![identify characters](identify_characters4.png)\n",
    "\n",
    "1. Retrieve our pre-processed book data from our __SQL__ database\n",
    "2. Obtain a stratified __sample__ (so that each book length remains representative)\n",
    "3. Do an initial pass to __extract__ named entities / proper nouns\n",
    "4. __Review__ the outputs and identify any __refinements__ we can make to the process to improve results\n",
    "5. __Extract__ named entities / proper nouns from the full books\n",
    "6. Get __name frequencies__ from the resulting data\n",
    "7. __Group similar names__ in an attempt to see if we can resolve similar character names like _Queen_ and _Queen of Hearts_\n",
    "8. __Evaluate__ the results\n",
    "\n",
    "In the development stage I will only use ```dickens```, ```carroll``` and ```alcott```. I am reserving ```bronte``` for the final evaluation step to gauge how transferable the proposed methods are to a book our model has not seen before.\n",
    "\n",
    "For each of the transformations required to arrive at the final output I'll create a function so that when it comes to processing ```bronte``` at the end I can just daisy-chain the functions together to get the final outputs for that book. It's beyond the scope of this project but ideally for productionizing one would want to create a library with suitable methods so that new books could easily be processed as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Retrieve pre-processed books data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_components = pd.read_sql_query \\\n",
    "('SELECT * FROM book_components WHERE author IN (\"dickens\", \"carroll\", \"alcott\")', 'sqlite:///book_store.db')\n",
    "book_components['lemmas'] = book_components['lemmas'].apply(lambda x: x.split(';'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Obtain a stratified sample from books\n",
    "\n",
    "For performance reasons, initially I'm just going to explore a stratified sample from the books so that I can check results and investigate the main issues that need to be resolved before moving on to processing the books in their entirety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = book_components.groupby\\\n",
    "('author', group_keys=False).apply(lambda x: x.sample(frac=0.2, random_state = 0)).index\n",
    "book_sample = book_components[book_components.index.isin(sample_indices)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many sentences we have from each book - the stratified sampling approach is inline with expectations (```carroll``` is much shorter than ```dickens``` or ```alcott```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcott</th>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carroll</th>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens</th>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence\n",
       "author           \n",
       "alcott       1866\n",
       "carroll       322\n",
       "dickens      1928"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(book_sample, index = ['author'], values = 'sentence', aggfunc = len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Initial pass to extract information\n",
    "\n",
    "Below I create and process 3 functions, each of which takes in some text and returns either named entities or proper nouns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK named entity recognition - ```get_named_entities_nltk()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_entities_nltk(text, ner_label_list = ['PERSON']):\n",
    "    '''Takes in text and a list of entity labels (default is just ['PERSON']) and returns a list\n",
    "    of tuples in the form (label, entity) - as processed by nltk.\n",
    "    Note the first time ne_chunk is used some downloads are required. Run the following:\n",
    "    >>> nltk.download('averaged_perceptron_tagger_eng')\n",
    "    >>> nltk.download('maxent_ne_chunker_tab')\n",
    "    '''\n",
    "    named_entity_tree = nltk.ne_chunk(nltk.tag.pos_tag(word_tokenize(text)))\n",
    "    named_entities = []\n",
    "    for tree in named_entity_tree.subtrees():\n",
    "        if tree.label() in ner_label_list:\n",
    "            named_entities.append((tree.label(), ' '.join([name[0] for name in tree.leaves()])))\n",
    "    if len(named_entities) > 0:\n",
    "        return named_entities\n",
    "    else:\n",
    "        return None # it's possible a sentence does not contain named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d75a3bc97d4c7bbf680bdf899ec91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_72311_row0_col7 {\n",
       "  background-color: gold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_72311\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_72311_level0_col0\" class=\"col_heading level0 col0\" >index</th>\n",
       "      <th id=\"T_72311_level0_col1\" class=\"col_heading level0 col1\" >author</th>\n",
       "      <th id=\"T_72311_level0_col2\" class=\"col_heading level0 col2\" >chapter</th>\n",
       "      <th id=\"T_72311_level0_col3\" class=\"col_heading level0 col3\" >paragraph</th>\n",
       "      <th id=\"T_72311_level0_col4\" class=\"col_heading level0 col4\" >sentence</th>\n",
       "      <th id=\"T_72311_level0_col5\" class=\"col_heading level0 col5\" >text</th>\n",
       "      <th id=\"T_72311_level0_col6\" class=\"col_heading level0 col6\" >lemmas</th>\n",
       "      <th id=\"T_72311_level0_col7\" class=\"col_heading level0 col7\" >nltk_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_72311_level0_row0\" class=\"row_heading level0 row0\" >9</th>\n",
       "      <td id=\"T_72311_row0_col0\" class=\"data row0 col0\" >9</td>\n",
       "      <td id=\"T_72311_row0_col1\" class=\"data row0 col1\" >dickens</td>\n",
       "      <td id=\"T_72311_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_72311_row0_col3\" class=\"data row0 col3\" >2</td>\n",
       "      <td id=\"T_72311_row0_col4\" class=\"data row0 col4\" >2</td>\n",
       "      <td id=\"T_72311_row0_col5\" class=\"data row0 col5\" >At such a time I found out for certain that this bleak place overgrown with nettles was the churchyard; and that Philip Pirrip, late of this parish, and also Georgiana wife of the above, were dead and buried; and that Alexander, Bartholomew, Abraham, Tobias, and Roger, infant children of the aforesaid, were also dead and buried; and that the dark flat wilderness beyond the churchyard, intersected with dikes and mounds and gates, with scattered cattle feeding on it, was the marshes; and that the low leaden line beyond was the river; and that the distant savage lair from which the wind was rushing was the sea; and that the small bundle of shivers growing afraid of it all and beginning to cry, was Pip.</td>\n",
       "      <td id=\"T_72311_row0_col6\" class=\"data row0 col6\" >['at', 'such', 'a', 'time', 'i', 'find', 'out', 'for', 'certain', 'that', 'this', 'bleak', 'place', 'overgrow', 'with', 'nettle', 'be', 'the', 'churchyard', 'and', 'that', 'philip', 'pirrip', 'late', 'of', 'this', 'parish', 'and', 'also', 'georgiana', 'wife', 'of', 'the', 'above', 'be', 'dead', 'and', 'bury', 'and', 'that', 'alexander', 'bartholomew', 'abraham', 'tobias', 'and', 'roger', 'infant', 'child', 'of', 'the', 'aforesaid', 'be', 'also', 'dead', 'and', 'bury', 'and', 'that', 'the', 'dark', 'flat', 'wilderness', 'beyond', 'the', 'churchyard', 'intersect', 'with', 'dike', 'and', 'mound', 'and', 'gate', 'with', 'scattered', 'cattle', 'feed', 'on', 'it', 'be', 'the', 'marsh', 'and', 'that', 'the', 'low', 'leaden', 'line', 'beyond', 'be', 'the', 'river', 'and', 'that', 'the', 'distant', 'savage', 'lair', 'from', 'which', 'the', 'wind', 'be', 'rush', 'be', 'the', 'sea', 'and', 'that', 'the', 'small', 'bundle', 'of', 'shiver', 'grow', 'afraid', 'of', 'it', 'all', 'and', 'begin', 'to', 'cry', 'be', 'pip']</td>\n",
       "      <td id=\"T_72311_row0_col7\" class=\"data row0 col7\" >[('PERSON', 'Philip Pirrip'), ('PERSON', 'Georgiana'), ('PERSON', 'Alexander'), ('PERSON', 'Roger'), ('PERSON', 'Pip')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x130a99880>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get named entities\n",
    "book_sample['nltk_entities'] = book_sample['text'].progress_apply(lambda x: get_named_entities_nltk(x))\n",
    "# Check outputs\n",
    "book_sample.head(1).style.apply(highlight_column, subset=['nltk_entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spaCy named entity recognition - ```get_named_entities_spacy()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_entities_spacy(text, ner_label_list = ['PERSON']):\n",
    "    '''Takes in text and a list of entity labels (default is just ['PERSON']) and returns a list\n",
    "    of tuples in the form (label, entity) - as processed by spacy'''\n",
    "    named_entities = [(ent.label_, ent.text) for ent in nlp(text).ents if ent.label_ in ner_label_list]\n",
    "    if len(named_entities) > 0:\n",
    "        return named_entities\n",
    "    else:\n",
    "        return None # it's possible a sentence does not contain named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4513fab3c143efa5c5c27cb21ccb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d2d05_row0_col8 {\n",
       "  background-color: gold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d2d05\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d2d05_level0_col0\" class=\"col_heading level0 col0\" >index</th>\n",
       "      <th id=\"T_d2d05_level0_col1\" class=\"col_heading level0 col1\" >author</th>\n",
       "      <th id=\"T_d2d05_level0_col2\" class=\"col_heading level0 col2\" >chapter</th>\n",
       "      <th id=\"T_d2d05_level0_col3\" class=\"col_heading level0 col3\" >paragraph</th>\n",
       "      <th id=\"T_d2d05_level0_col4\" class=\"col_heading level0 col4\" >sentence</th>\n",
       "      <th id=\"T_d2d05_level0_col5\" class=\"col_heading level0 col5\" >text</th>\n",
       "      <th id=\"T_d2d05_level0_col6\" class=\"col_heading level0 col6\" >lemmas</th>\n",
       "      <th id=\"T_d2d05_level0_col7\" class=\"col_heading level0 col7\" >nltk_entities</th>\n",
       "      <th id=\"T_d2d05_level0_col8\" class=\"col_heading level0 col8\" >spacy_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d2d05_level0_row0\" class=\"row_heading level0 row0\" >9</th>\n",
       "      <td id=\"T_d2d05_row0_col0\" class=\"data row0 col0\" >9</td>\n",
       "      <td id=\"T_d2d05_row0_col1\" class=\"data row0 col1\" >dickens</td>\n",
       "      <td id=\"T_d2d05_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_d2d05_row0_col3\" class=\"data row0 col3\" >2</td>\n",
       "      <td id=\"T_d2d05_row0_col4\" class=\"data row0 col4\" >2</td>\n",
       "      <td id=\"T_d2d05_row0_col5\" class=\"data row0 col5\" >At such a time I found out for certain that this bleak place overgrown with nettles was the churchyard; and that Philip Pirrip, late of this parish, and also Georgiana wife of the above, were dead and buried; and that Alexander, Bartholomew, Abraham, Tobias, and Roger, infant children of the aforesaid, were also dead and buried; and that the dark flat wilderness beyond the churchyard, intersected with dikes and mounds and gates, with scattered cattle feeding on it, was the marshes; and that the low leaden line beyond was the river; and that the distant savage lair from which the wind was rushing was the sea; and that the small bundle of shivers growing afraid of it all and beginning to cry, was Pip.</td>\n",
       "      <td id=\"T_d2d05_row0_col6\" class=\"data row0 col6\" >['at', 'such', 'a', 'time', 'i', 'find', 'out', 'for', 'certain', 'that', 'this', 'bleak', 'place', 'overgrow', 'with', 'nettle', 'be', 'the', 'churchyard', 'and', 'that', 'philip', 'pirrip', 'late', 'of', 'this', 'parish', 'and', 'also', 'georgiana', 'wife', 'of', 'the', 'above', 'be', 'dead', 'and', 'bury', 'and', 'that', 'alexander', 'bartholomew', 'abraham', 'tobias', 'and', 'roger', 'infant', 'child', 'of', 'the', 'aforesaid', 'be', 'also', 'dead', 'and', 'bury', 'and', 'that', 'the', 'dark', 'flat', 'wilderness', 'beyond', 'the', 'churchyard', 'intersect', 'with', 'dike', 'and', 'mound', 'and', 'gate', 'with', 'scattered', 'cattle', 'feed', 'on', 'it', 'be', 'the', 'marsh', 'and', 'that', 'the', 'low', 'leaden', 'line', 'beyond', 'be', 'the', 'river', 'and', 'that', 'the', 'distant', 'savage', 'lair', 'from', 'which', 'the', 'wind', 'be', 'rush', 'be', 'the', 'sea', 'and', 'that', 'the', 'small', 'bundle', 'of', 'shiver', 'grow', 'afraid', 'of', 'it', 'all', 'and', 'begin', 'to', 'cry', 'be', 'pip']</td>\n",
       "      <td id=\"T_d2d05_row0_col7\" class=\"data row0 col7\" >[('PERSON', 'Philip Pirrip'), ('PERSON', 'Georgiana'), ('PERSON', 'Alexander'), ('PERSON', 'Roger'), ('PERSON', 'Pip')]</td>\n",
       "      <td id=\"T_d2d05_row0_col8\" class=\"data row0 col8\" >[('PERSON', 'Alexander'), ('PERSON', 'Bartholomew'), ('PERSON', 'Abraham'), ('PERSON', 'Tobias'), ('PERSON', 'Roger'), ('PERSON', 'Pip')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x136de44a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get named entities\n",
    "book_sample['spacy_entities'] = book_sample['text'].progress_apply(lambda x: get_named_entities_spacy(x))\n",
    "# Check outputs\n",
    "book_sample.head(1).style.apply(highlight_column, subset=['spacy_entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK proper noun extraction - ```get_proper_nouns_nltk()```\n",
    "\n",
    "In reviewing the character names, especially with Alice I noticed character names like _Queen of Hearts_ where the preposition 'of' occurs between the 2 proper nouns. It's important to see this as one thing, rather than three so I'm catering for that here. In addition compound names like _Billy the Kid_ are in common use so I'm including the determiner _the_ in this recipe too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proper_nouns_nltk(text):\n",
    "    '''Takes in text and returns a list of proper nouns (or consecutive proper nouns \n",
    "    like \"Mrs. Smith\" if applicable). Also caters for compound proper nouns formed with\n",
    "    \"of\" or \"the\" such as \"Richard of Orange\" or \"Billy the Kid\"'''\n",
    "    consecutive_tokens = nltk.tag.pos_tag(word_tokenize(text))\n",
    "    # Structure to hold final list of proper nouns\n",
    "    proper_nouns = []\n",
    "    # Temporary structure in which to build up proper nouns\n",
    "    name_list = []\n",
    "    for (word, pos) in consecutive_tokens:\n",
    "        if pos == 'NNP' or word.lower() in ['of', 'the']:\n",
    "            name_list.append(word)\n",
    "        elif len(name_list) > 0:\n",
    "            full_name = ' '.join(name_list)\n",
    "            # Remove any leading 'of' and 'the' instances\n",
    "            full_name = re.sub(r'((( ?[Tt]he)|( ?[Oo]f)))+$', '', \\\n",
    "                               re.sub(r'(^(([Tt]he ?)|([Oo]f ?))+)', '', full_name))\n",
    "            if full_name != '':\n",
    "                proper_nouns.append(full_name)\n",
    "            name_list = []\n",
    "    if len(proper_nouns) > 0:\n",
    "        return proper_nouns\n",
    "    else:\n",
    "        return None # it's possible a sentence does not contain any proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a28953dd6794307baeba37226a3bfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1f6b2_row0_col9 {\n",
       "  background-color: gold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1f6b2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1f6b2_level0_col0\" class=\"col_heading level0 col0\" >index</th>\n",
       "      <th id=\"T_1f6b2_level0_col1\" class=\"col_heading level0 col1\" >author</th>\n",
       "      <th id=\"T_1f6b2_level0_col2\" class=\"col_heading level0 col2\" >chapter</th>\n",
       "      <th id=\"T_1f6b2_level0_col3\" class=\"col_heading level0 col3\" >paragraph</th>\n",
       "      <th id=\"T_1f6b2_level0_col4\" class=\"col_heading level0 col4\" >sentence</th>\n",
       "      <th id=\"T_1f6b2_level0_col5\" class=\"col_heading level0 col5\" >text</th>\n",
       "      <th id=\"T_1f6b2_level0_col6\" class=\"col_heading level0 col6\" >lemmas</th>\n",
       "      <th id=\"T_1f6b2_level0_col7\" class=\"col_heading level0 col7\" >nltk_entities</th>\n",
       "      <th id=\"T_1f6b2_level0_col8\" class=\"col_heading level0 col8\" >spacy_entities</th>\n",
       "      <th id=\"T_1f6b2_level0_col9\" class=\"col_heading level0 col9\" >proper_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1f6b2_level0_row0\" class=\"row_heading level0 row0\" >9</th>\n",
       "      <td id=\"T_1f6b2_row0_col0\" class=\"data row0 col0\" >9</td>\n",
       "      <td id=\"T_1f6b2_row0_col1\" class=\"data row0 col1\" >dickens</td>\n",
       "      <td id=\"T_1f6b2_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_1f6b2_row0_col3\" class=\"data row0 col3\" >2</td>\n",
       "      <td id=\"T_1f6b2_row0_col4\" class=\"data row0 col4\" >2</td>\n",
       "      <td id=\"T_1f6b2_row0_col5\" class=\"data row0 col5\" >At such a time I found out for certain that this bleak place overgrown with nettles was the churchyard; and that Philip Pirrip, late of this parish, and also Georgiana wife of the above, were dead and buried; and that Alexander, Bartholomew, Abraham, Tobias, and Roger, infant children of the aforesaid, were also dead and buried; and that the dark flat wilderness beyond the churchyard, intersected with dikes and mounds and gates, with scattered cattle feeding on it, was the marshes; and that the low leaden line beyond was the river; and that the distant savage lair from which the wind was rushing was the sea; and that the small bundle of shivers growing afraid of it all and beginning to cry, was Pip.</td>\n",
       "      <td id=\"T_1f6b2_row0_col6\" class=\"data row0 col6\" >['at', 'such', 'a', 'time', 'i', 'find', 'out', 'for', 'certain', 'that', 'this', 'bleak', 'place', 'overgrow', 'with', 'nettle', 'be', 'the', 'churchyard', 'and', 'that', 'philip', 'pirrip', 'late', 'of', 'this', 'parish', 'and', 'also', 'georgiana', 'wife', 'of', 'the', 'above', 'be', 'dead', 'and', 'bury', 'and', 'that', 'alexander', 'bartholomew', 'abraham', 'tobias', 'and', 'roger', 'infant', 'child', 'of', 'the', 'aforesaid', 'be', 'also', 'dead', 'and', 'bury', 'and', 'that', 'the', 'dark', 'flat', 'wilderness', 'beyond', 'the', 'churchyard', 'intersect', 'with', 'dike', 'and', 'mound', 'and', 'gate', 'with', 'scattered', 'cattle', 'feed', 'on', 'it', 'be', 'the', 'marsh', 'and', 'that', 'the', 'low', 'leaden', 'line', 'beyond', 'be', 'the', 'river', 'and', 'that', 'the', 'distant', 'savage', 'lair', 'from', 'which', 'the', 'wind', 'be', 'rush', 'be', 'the', 'sea', 'and', 'that', 'the', 'small', 'bundle', 'of', 'shiver', 'grow', 'afraid', 'of', 'it', 'all', 'and', 'begin', 'to', 'cry', 'be', 'pip']</td>\n",
       "      <td id=\"T_1f6b2_row0_col7\" class=\"data row0 col7\" >[('PERSON', 'Philip Pirrip'), ('PERSON', 'Georgiana'), ('PERSON', 'Alexander'), ('PERSON', 'Roger'), ('PERSON', 'Pip')]</td>\n",
       "      <td id=\"T_1f6b2_row0_col8\" class=\"data row0 col8\" >[('PERSON', 'Alexander'), ('PERSON', 'Bartholomew'), ('PERSON', 'Abraham'), ('PERSON', 'Tobias'), ('PERSON', 'Roger'), ('PERSON', 'Pip')]</td>\n",
       "      <td id=\"T_1f6b2_row0_col9\" class=\"data row0 col9\" >['Philip Pirrip', 'Georgiana', 'Alexander', 'Bartholomew', 'Abraham', 'Tobias', 'Roger', 'Pip']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x136e076e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get proper nouns\n",
    "book_sample['proper_nouns'] = book_sample['text'].progress_apply(lambda x: get_proper_nouns_nltk(x))\n",
    "# Check outputs\n",
    "book_sample.head(1).style.apply(highlight_column, subset=['proper_nouns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Review the outputs and look for possible method refinements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 3.4.1 Quality of the outputs / issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a sample of results from ```dickens```. Below we see some pitfalls with NER already:\n",
    "\n",
    "* _Miss Havisham_ is missed by __spaCy__ in the second sentence and incorrectly truncated to just _Havisham_ in the fourth\n",
    "* In the third sentence only _Abel_ is recognised by __NLTK__ but only _Magwitch_ is recognised by __spaCy__\n",
    "* _Pip_ is missed by both in the fifth sentence\n",
    "\n",
    "Proper nouns look better, with all the characters present and correct, BUT:\n",
    "\n",
    "* An apostrophe has also been identified as a proper noun which is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>chapter</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>nltk_entities</th>\n",
       "      <th>spacy_entities</th>\n",
       "      <th>proper_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>6106</td>\n",
       "      <td>dickens</td>\n",
       "      <td>37</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>“Why should I look at him?” returned Estella, with her eyes on me instead.</td>\n",
       "      <td>[why, should, i, look, at, he, return, estella, with, her, eye, on, i, instead]</td>\n",
       "      <td>[(PERSON, Estella)]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Estella]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>dickens</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>“You are to wait here, you boy,” said Estella; and disappeared and closed the door.</td>\n",
       "      <td>[you, be, to, wait, here, you, boy, say, estella, and, disappear, and, close, the, door]</td>\n",
       "      <td>[(PERSON, Estella)]</td>\n",
       "      <td>None</td>\n",
       "      <td>[”, Estella]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>8200</td>\n",
       "      <td>dickens</td>\n",
       "      <td>51</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>“Pip,” said Mr. Jaggers, laying his hand upon my arm, and smiling openly, “this man must be the most cunning impostor in all London.”</td>\n",
       "      <td>[pip, say, mr., jaggers, lay, his, hand, upon, my, arm, and, smile, openly, this, man, must, be, the, most, cunning, impostor, in, all, london]</td>\n",
       "      <td>[(PERSON, Pip), (PERSON, Mr. Jaggers)]</td>\n",
       "      <td>[(PERSON, Jaggers)]</td>\n",
       "      <td>[Pip, ”, Mr. Jaggers, London]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>1358</td>\n",
       "      <td>dickens</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>“Yes,” said I. “Estella waved a blue flag, and I waved a red one, and Miss Havisham waved one sprinkled all over with little gold stars, out at the coach-window.</td>\n",
       "      <td>[yes, say, i., estella, wave, a, blue, flag, and, i, wave, a, red, one, and, miss, havisham, wave, one, sprinkle, all, over, with, little, gold, star, out, at, the, coach, window]</td>\n",
       "      <td>[(PERSON, Estella), (PERSON, Miss Havisham)]</td>\n",
       "      <td>[(PERSON, I. “Estella), (PERSON, Havisham)]</td>\n",
       "      <td>[Yes, ”, Estella, Miss Havisham]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>2620</td>\n",
       "      <td>dickens</td>\n",
       "      <td>16</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>And now, because my mind was not confused enough before, I complicated its confusion fifty thousand-fold, by having states and seasons when I was clear that Biddy was immeasurably better than Estella, and that the plain honest working life to which I was born had nothing in it to be ashamed of, but offered me sufficient means of self-respect and happiness.</td>\n",
       "      <td>[and, now, because, my, mind, be, not, confuse, enough, before, i, complicate, its, confusion, fifty, thousand, -, fold, by, have, state, and, season, when, i, be, clear, that, biddy, be, immeasurably, well, than, estella, and, that, the, plain, honest, work, life, to, which, i, be, bear, have, nothing, in, it, to, be, ashamed, of, but, offer, i, sufficient, mean, of, self, respect, and, happiness]</td>\n",
       "      <td>[(PERSON, Biddy), (PERSON, Estella)]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Biddy, Estella]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   author chapter paragraph sentence  \\\n",
       "6106   6106  dickens      37        86        0   \n",
       "1231   1231  dickens       7        91        0   \n",
       "8200   8200  dickens      51        33        0   \n",
       "1358   1358  dickens       8        37        0   \n",
       "2620   2620  dickens      16        73        0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "6106                                                                                                                                                                                                                                                                                              “Why should I look at him?” returned Estella, with her eyes on me instead.   \n",
       "1231                                                                                                                                                                                                                                                                                     “You are to wait here, you boy,” said Estella; and disappeared and closed the door.   \n",
       "8200                                                                                                                                                                                                                                   “Pip,” said Mr. Jaggers, laying his hand upon my arm, and smiling openly, “this man must be the most cunning impostor in all London.”   \n",
       "1358                                                                                                                                                                                                       “Yes,” said I. “Estella waved a blue flag, and I waved a red one, and Miss Havisham waved one sprinkled all over with little gold stars, out at the coach-window.   \n",
       "2620  And now, because my mind was not confused enough before, I complicated its confusion fifty thousand-fold, by having states and seasons when I was clear that Biddy was immeasurably better than Estella, and that the plain honest working life to which I was born had nothing in it to be ashamed of, but offered me sufficient means of self-respect and happiness.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                 lemmas  \\\n",
       "6106                                                                                                                                                                                                                                                                                                                                    [why, should, i, look, at, he, return, estella, with, her, eye, on, i, instead]   \n",
       "1231                                                                                                                                                                                                                                                                                                                           [you, be, to, wait, here, you, boy, say, estella, and, disappear, and, close, the, door]   \n",
       "8200                                                                                                                                                                                                                                                                    [pip, say, mr., jaggers, lay, his, hand, upon, my, arm, and, smile, openly, this, man, must, be, the, most, cunning, impostor, in, all, london]   \n",
       "1358                                                                                                                                                                                                                                [yes, say, i., estella, wave, a, blue, flag, and, i, wave, a, red, one, and, miss, havisham, wave, one, sprinkle, all, over, with, little, gold, star, out, at, the, coach, window]   \n",
       "2620  [and, now, because, my, mind, be, not, confuse, enough, before, i, complicate, its, confusion, fifty, thousand, -, fold, by, have, state, and, season, when, i, be, clear, that, biddy, be, immeasurably, well, than, estella, and, that, the, plain, honest, work, life, to, which, i, be, bear, have, nothing, in, it, to, be, ashamed, of, but, offer, i, sufficient, mean, of, self, respect, and, happiness]   \n",
       "\n",
       "                                     nltk_entities  \\\n",
       "6106                           [(PERSON, Estella)]   \n",
       "1231                           [(PERSON, Estella)]   \n",
       "8200        [(PERSON, Pip), (PERSON, Mr. Jaggers)]   \n",
       "1358  [(PERSON, Estella), (PERSON, Miss Havisham)]   \n",
       "2620          [(PERSON, Biddy), (PERSON, Estella)]   \n",
       "\n",
       "                                   spacy_entities  \\\n",
       "6106                                         None   \n",
       "1231                                         None   \n",
       "8200                          [(PERSON, Jaggers)]   \n",
       "1358  [(PERSON, I. “Estella), (PERSON, Havisham)]   \n",
       "2620                                         None   \n",
       "\n",
       "                          proper_nouns  \n",
       "6106                         [Estella]  \n",
       "1231                      [”, Estella]  \n",
       "8200     [Pip, ”, Mr. Jaggers, London]  \n",
       "1358  [Yes, ”, Estella, Miss Havisham]  \n",
       "2620                  [Biddy, Estella]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_sample[(book_sample['author'] == 'dickens') & \\\n",
    "            (book_sample['text'].str.contains('Pip|Havisham|Estella|Abel'))].sample(5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sample indices so that we can look at the examples again later\n",
    "sample_indices = book_sample[(book_sample['author'] == 'dickens') & \\\n",
    "         (book_sample['text'].str.contains('Pip|Havisham|Estella|Abel'))].sample\\\n",
    "(5, random_state=5).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm expecting trouble with ```carroll```. The way these characters are referenced is not typical of most training corpora: referring to a character as '_the Duchess_' or '_the Caterpillar_' is a little unusual. And indeed with NER the results are terrible:\n",
    "\n",
    "* None of the 'odd' characters like _Caterpillar_ and _Duchess_ have been identified - in fact only _Alice_ herself in the fifth sentence gets picked up\n",
    "\n",
    "The proper nouns do at least pick out these capitalised characters, however:\n",
    "\n",
    "* _No_ and _Very_ are being picked up as proper nouns which is incorrect. Once again there are apostrophes, and now quotation marks too, included. These definitely need further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>chapter</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>nltk_entities</th>\n",
       "      <th>spacy_entities</th>\n",
       "      <th>proper_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10575</th>\n",
       "      <td>10575</td>\n",
       "      <td>carroll</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Next came the guests, mostly Kings and Queens, and among them Alice recognised the White Rabbit: it was talking in a hurried nervous manner, smiling at everything that was said, and went by without noticing her.</td>\n",
       "      <td>[next, come, the, guest, mostly, king, and, queens, and, among, they, alice, recognise, the, white, rabbit, it, be, talk, in, a, hurried, nervous, manner, smile, at, everything, that, be, say, and, go, by, without, notice, she]</td>\n",
       "      <td>[(PERSON, Next), (PERSON, Kings)]</td>\n",
       "      <td>[(PERSON, Kings), (PERSON, Alice)]</td>\n",
       "      <td>[Kings, Queens, Alice, White]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10712</th>\n",
       "      <td>10712</td>\n",
       "      <td>carroll</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>“Very true,” said the Duchess: “flamingoes and mustard both bite.</td>\n",
       "      <td>[very, true, say, the, duchess, flamingo, and, mustard, both, bite]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Very, ”]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>10120</td>\n",
       "      <td>carroll</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>“Why?” said the Caterpillar.</td>\n",
       "      <td>[why, say, the, caterpillar]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Caterpillar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11189</th>\n",
       "      <td>11189</td>\n",
       "      <td>carroll</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>The White Rabbit put on his spectacles.</td>\n",
       "      <td>[the, white, rabbit, put, on, his, spectacle]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[White Rabbit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11244</th>\n",
       "      <td>11244</td>\n",
       "      <td>carroll</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>The long grass rustled at her feet as the White Rabbit hurried by—the frightened Mouse splashed his way through the neighbouring pool—she could hear the rattle of the teacups as the March Hare and his friends shared their never-ending meal, and the shrill voice of the Queen ordering off her unfortunate guests to execution—once more the pig-baby was sneezing on the Duchess’s knee, while plates and dishes crashed around it—once more the shriek of the Gryphon, the squeaking of the Lizard’s slat...</td>\n",
       "      <td>[the, long, grass, rustle, at, her, foot, as, the, white, rabbit, hurry, by, the, frightened, mouse, splash, his, way, through, the, neighbour, pool, she, could, hear, the, rattle, of, the, teacup, as, the, march, hare, and, his, friend, share, their, never, end, meal, and, the, shrill, voice, of, the, queen, order, off, her, unfortunate, guest, to, execution, once, more, the, pig, baby, be, sneeze, on, the, duchess, knee, while, plate, and, dish, crash, around, it, once, more, the, shriek, ...</td>\n",
       "      <td>[(PERSON, Mouse), (PERSON, Mock Turtle)]</td>\n",
       "      <td>[(PERSON, Mouse), (PERSON, Queen)]</td>\n",
       "      <td>[White Rabbit, Mouse, March Hare, Queen, Duchess ’, Gryphon, Lizard ’, Mock Turtle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   author chapter paragraph sentence  \\\n",
       "10575  10575  carroll       7        10        2   \n",
       "10712  10712  carroll       8        14        0   \n",
       "10120  10120  carroll       4        13        0   \n",
       "11189  11189  carroll      11        37        0   \n",
       "11244  11244  carroll      11        68        0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "10575                                                                                                                                                                                                                                                                                                  Next came the guests, mostly Kings and Queens, and among them Alice recognised the White Rabbit: it was talking in a hurried nervous manner, smiling at everything that was said, and went by without noticing her.   \n",
       "10712                                                                                                                                                                                                                                                                                                                                                                                                                                                    “Very true,” said the Duchess: “flamingoes and mustard both bite.   \n",
       "10120                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         “Why?” said the Caterpillar.   \n",
       "11189                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The White Rabbit put on his spectacles.   \n",
       "11244  The long grass rustled at her feet as the White Rabbit hurried by—the frightened Mouse splashed his way through the neighbouring pool—she could hear the rattle of the teacups as the March Hare and his friends shared their never-ending meal, and the shrill voice of the Queen ordering off her unfortunate guests to execution—once more the pig-baby was sneezing on the Duchess’s knee, while plates and dishes crashed around it—once more the shriek of the Gryphon, the squeaking of the Lizard’s slat...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    lemmas  \\\n",
       "10575                                                                                                                                                                                                                                                                                  [next, come, the, guest, mostly, king, and, queens, and, among, they, alice, recognise, the, white, rabbit, it, be, talk, in, a, hurried, nervous, manner, smile, at, everything, that, be, say, and, go, by, without, notice, she]   \n",
       "10712                                                                                                                                                                                                                                                                                                                                                                                                                                                  [very, true, say, the, duchess, flamingo, and, mustard, both, bite]   \n",
       "10120                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [why, say, the, caterpillar]   \n",
       "11189                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [the, white, rabbit, put, on, his, spectacle]   \n",
       "11244  [the, long, grass, rustle, at, her, foot, as, the, white, rabbit, hurry, by, the, frightened, mouse, splash, his, way, through, the, neighbour, pool, she, could, hear, the, rattle, of, the, teacup, as, the, march, hare, and, his, friend, share, their, never, end, meal, and, the, shrill, voice, of, the, queen, order, off, her, unfortunate, guest, to, execution, once, more, the, pig, baby, be, sneeze, on, the, duchess, knee, while, plate, and, dish, crash, around, it, once, more, the, shriek, ...   \n",
       "\n",
       "                                  nltk_entities  \\\n",
       "10575         [(PERSON, Next), (PERSON, Kings)]   \n",
       "10712                                      None   \n",
       "10120                                      None   \n",
       "11189                                      None   \n",
       "11244  [(PERSON, Mouse), (PERSON, Mock Turtle)]   \n",
       "\n",
       "                           spacy_entities  \\\n",
       "10575  [(PERSON, Kings), (PERSON, Alice)]   \n",
       "10712                                None   \n",
       "10120                                None   \n",
       "11189                                None   \n",
       "11244  [(PERSON, Mouse), (PERSON, Queen)]   \n",
       "\n",
       "                                                                              proper_nouns  \n",
       "10575                                                        [Kings, Queens, Alice, White]  \n",
       "10712                                                                            [Very, ”]  \n",
       "10120                                                                        [Caterpillar]  \n",
       "11189                                                                       [White Rabbit]  \n",
       "11244  [White Rabbit, Mouse, March Hare, Queen, Duchess ’, Gryphon, Lizard ’, Mock Turtle]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_sample[(book_sample['author'] == 'carroll') & \\\n",
    "            (book_sample['text'].str.contains('White Rabbit|Caterpillar|Duchess'))].sample(5, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sample indices so that we can look at the examples again later\n",
    "sample_indices.extend(book_sample[(book_sample['author'] == 'carroll') & \\\n",
    "  (book_sample['text'].str.contains('White Rabbit|Caterpillar|Duchess'))].sample(5, random_state=15).index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining results from ```alcott``` we see similar issues with NER:\n",
    "\n",
    "* _Meg_ has been missed by __NLTK__ and __spaCy__ in the first sentence\n",
    "* In the second sentence _Amy_ is missed by __spaCy__, and _Hall_ is erroneously included\n",
    "\n",
    "And as before with proper nouns we see:\n",
    "\n",
    "* _Aren_ has been picked up as a proper noun (and also as a person by __NLTK__), and once again those extraneous punctuation marks are labelled as proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>chapter</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>nltk_entities</th>\n",
       "      <th>spacy_entities</th>\n",
       "      <th>proper_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20565</th>\n",
       "      <td>20565</td>\n",
       "      <td>alcott</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>“There’s no need for me to say it, for everyone can see that I’m far happier than I deserve,” added Jo, glancing from her good husband to her chubby children, tumbling on the grass beside her.</td>\n",
       "      <td>[there, ’, no, need, for, i, to, say, it, for, everyone, can, see, that, i, am, far, happy, than, i, deserve, add, jo, glance, from, her, good, husband, to, her, chubby, child, tumble, on, the, grass, beside, she]</td>\n",
       "      <td>[(PERSON, Jo)]</td>\n",
       "      <td>[(PERSON, Jo)]</td>\n",
       "      <td>[’, ”, Jo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16890</th>\n",
       "      <td>16890</td>\n",
       "      <td>alcott</td>\n",
       "      <td>29</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>I wouldn’t have told you, for I set my heart on surprising you, and I flatter myself I’ve done it,” said Jo, when she got her breath.</td>\n",
       "      <td>[i, would, not, have, tell, you, for, i, set, my, heart, on, surprise, you, and, i, flatter, myself, i, have, do, it, say, jo, when, she, get, her, breath]</td>\n",
       "      <td>[(PERSON, Jo)]</td>\n",
       "      <td>[(PERSON, Jo)]</td>\n",
       "      <td>[”, Jo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td>19810</td>\n",
       "      <td>alcott</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>“You are the same Jo still, dropping tears about one minute, and laughing the next.</td>\n",
       "      <td>[you, be, the, same, jo, still, drop, tear, about, one, minute, and, laugh, the, next]</td>\n",
       "      <td>None</td>\n",
       "      <td>[(PERSON, Jo)]</td>\n",
       "      <td>[Jo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17687</th>\n",
       "      <td>17687</td>\n",
       "      <td>alcott</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>I’ve tried, because one feels awkward in company not to do as everybody else is doing, but I don’t seem to get on”, said Jo, forgetting to play mentor.</td>\n",
       "      <td>[i, have, try, because, one, feel, awkward, in, company, not, to, do, as, everybody, else, be, do, but, i, do, not, seem, to, get, on, say, jo, forget, to, play, mentor]</td>\n",
       "      <td>[(PERSON, Jo)]</td>\n",
       "      <td>[(PERSON, Jo)]</td>\n",
       "      <td>[Jo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16979</th>\n",
       "      <td>16979</td>\n",
       "      <td>alcott</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>Just be calm, cool, and quiet, that’s safe and ladylike, and you can easily do it for fifteen minutes,” said Amy, as they approached the first place, having borrowed the white parasol and been inspected by Meg, with a baby on each arm.</td>\n",
       "      <td>[just, be, calm, cool, and, quiet, that, ’, safe, and, ladylike, and, you, can, easily, do, it, for, fifteen, minute, say, amy, as, they, approach, the, first, place, having, borrow, the, white, parasol, and, be, inspect, by, meg, with, a, baby, on, each, arm]</td>\n",
       "      <td>[(PERSON, Amy), (PERSON, Meg)]</td>\n",
       "      <td>[(PERSON, Amy)]</td>\n",
       "      <td>[’, ”, Amy, Meg]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  author chapter paragraph sentence  \\\n",
       "20565  20565  alcott      48        52        0   \n",
       "16890  16890  alcott      29        78        1   \n",
       "19810  19810  alcott      44        58        0   \n",
       "17687  17687  alcott      33        38        1   \n",
       "16979  16979  alcott      30        19        2   \n",
       "\n",
       "                                                                                                                                                                                                                                              text  \\\n",
       "20565                                             “There’s no need for me to say it, for everyone can see that I’m far happier than I deserve,” added Jo, glancing from her good husband to her chubby children, tumbling on the grass beside her.   \n",
       "16890                                                                                                        I wouldn’t have told you, for I set my heart on surprising you, and I flatter myself I’ve done it,” said Jo, when she got her breath.   \n",
       "19810                                                                                                                                                          “You are the same Jo still, dropping tears about one minute, and laughing the next.   \n",
       "17687                                                                                      I’ve tried, because one feels awkward in company not to do as everybody else is doing, but I don’t seem to get on”, said Jo, forgetting to play mentor.   \n",
       "16979  Just be calm, cool, and quiet, that’s safe and ladylike, and you can easily do it for fifteen minutes,” said Amy, as they approached the first place, having borrowed the white parasol and been inspected by Meg, with a baby on each arm.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                     lemmas  \\\n",
       "20565                                                 [there, ’, no, need, for, i, to, say, it, for, everyone, can, see, that, i, am, far, happy, than, i, deserve, add, jo, glance, from, her, good, husband, to, her, chubby, child, tumble, on, the, grass, beside, she]   \n",
       "16890                                                                                                           [i, would, not, have, tell, you, for, i, set, my, heart, on, surprise, you, and, i, flatter, myself, i, have, do, it, say, jo, when, she, get, her, breath]   \n",
       "19810                                                                                                                                                                                [you, be, the, same, jo, still, drop, tear, about, one, minute, and, laugh, the, next]   \n",
       "17687                                                                                             [i, have, try, because, one, feel, awkward, in, company, not, to, do, as, everybody, else, be, do, but, i, do, not, seem, to, get, on, say, jo, forget, to, play, mentor]   \n",
       "16979  [just, be, calm, cool, and, quiet, that, ’, safe, and, ladylike, and, you, can, easily, do, it, for, fifteen, minute, say, amy, as, they, approach, the, first, place, having, borrow, the, white, parasol, and, be, inspect, by, meg, with, a, baby, on, each, arm]   \n",
       "\n",
       "                        nltk_entities   spacy_entities      proper_nouns  \n",
       "20565                  [(PERSON, Jo)]   [(PERSON, Jo)]        [’, ”, Jo]  \n",
       "16890                  [(PERSON, Jo)]   [(PERSON, Jo)]           [”, Jo]  \n",
       "19810                            None   [(PERSON, Jo)]              [Jo]  \n",
       "17687                  [(PERSON, Jo)]   [(PERSON, Jo)]              [Jo]  \n",
       "16979  [(PERSON, Amy), (PERSON, Meg)]  [(PERSON, Amy)]  [’, ”, Amy, Meg]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_sample[(book_sample['author'] == 'alcott') & \\\n",
    "            (book_sample['text'].str.contains('Jo|Meg|Amy'))].sample(5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sample indices so that we can look at the examples again later\n",
    "sample_indices.extend(book_sample[(book_sample['author'] == 'alcott') & \\\n",
    "                      (book_sample['text'].str.contains('Jo|Meg|Amy'))].sample(5, random_state=5).index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a look at the inner workings of the _Aren_ example from ```alcott```, we can see that our punctuation is being dealt with incorrectly (run ```nltk.help.upenn_tagset()``` for a list of the Penn Treebank tags and their meanings if required): \n",
    "\n",
    "* ```('“', 'JJ')``` - this is not an adjective\n",
    "* ```('’', 'NNP')``` - this is not a proper noun\n",
    "* ```('”', 'VB')``` - this is not a verb\n",
    "\n",
    "This incorrect handling of punctuation is not only causing punctuation to be returned as proper nouns, but it's also affecting the tagging of surrounding terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "11559",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dsm020/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 11559",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mbook_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11559\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m pos_tree \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtag\u001b[38;5;241m.\u001b[39mpos_tag(word_tokenize(sample))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m'''\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsm020/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsm020/lib/python3.12/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsm020/lib/python3.12/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsm020/lib/python3.12/site-packages/pandas/core/generic.py:4301\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4299\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4301\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/miniconda3/envs/dsm020/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 11559"
     ]
    }
   ],
   "source": [
    "sample = book_sample.loc[11559]['text']\n",
    "pos_tree = nltk.tag.pos_tag(word_tokenize(sample))\n",
    "print(f'''{sample}\n",
    "''')\n",
    "for tree in pos_tree:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar pattern with the _Very_ example from ```alcott``` where the surrounding punctuation is incorrectly tagged and _Very_ itself is tagged as a proper noun ```NNP```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = book_sample.loc[10378]['text']\n",
    "pos_tree = nltk.tag.pos_tag(word_tokenize(sample))\n",
    "print(f'''{sample}\n",
    "''')\n",
    "for tree in pos_tree:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It struck me that these apostrophes and quotation marks differ from the standard modern ones. I wondered whether changing ```‘’``` to ```''``` and ```“”``` to ```\"\"``` would resolve the issue as they are more common in modern corpora, and indeed it does: in the following example ```\"``` is now tagged as punctuation, and as a result _Very_ has correctly been tagged as an adverb (```RB```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_sample = '''\"Very,\" said Alice: \" - where's the Duchess?\"'''\n",
    "pos_tree = nltk.tag.pos_tag(word_tokenize(adjusted_sample))\n",
    "print(f'''{adjusted_sample}\n",
    "''')\n",
    "for tree in pos_tree:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the punctuation we have across all 3 full books and see if there are any other irregular items that stand out. In an offline exercise I also investigated the difference between ```-``` and ```—``` (dashes and hyphens respectively) but found they did not have a negative impact on the tagging. I also looked at the impact of these characters: ```[]&*$```, but their presence was negligible and therefore no changes were required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_df = book_components['text'].str.extractall(r'([^\\w\\s])').reset_index(drop=True)\n",
    "punctuation_list = punctuation_df[0].unique()\n",
    "punctuation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I'm going to go ahead and replace our 'abnormal' punctuation with 'normal' punctuation in our ```book_sample```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_replacements = {'“':'\"', '”':'\"', '‘':\"'\", '’':\"'\" }\n",
    "for before, after in punctuation_replacements.items():\n",
    "    book_sample['text'] = book_sample['text'].str.replace(before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now repeat the NER / POS tagging tasks so we can check the effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_sample['nltk_entities_v2'] = book_sample['text'].progress_apply(lambda x: get_named_entities_nltk(x))\n",
    "book_sample['spacy_entities_v2'] = book_sample['text'].progress_apply(lambda x: get_named_entities_spacy(x))\n",
    "book_sample['proper_nouns_v2'] = book_sample['text'].progress_apply(lambda x: get_proper_nouns_nltk(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This change has resolved the edge cases to do with punctuation that we identified earlier (compare the outputs of the original columns with the ```*_v2``` columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_columns = ['author', 'text', 'nltk_entities', 'spacy_entities', 'proper_nouns', 'nltk_entities_v2',\n",
    "       'spacy_entities_v2', 'proper_nouns_v2']\n",
    "book_sample.loc[book_sample.index.isin(sample_indices), view_columns].style.apply\\\n",
    "(highlight_column, subset=['nltk_entities_v2', 'spacy_entities_v2', 'proper_nouns_v2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Names with titles\n",
    "\n",
    "Another aspect that I want to look into is the use of titles like _Mr._ and _Mrs._ as these are less common in modern corpora. When it comes to _Mr._ results for NER are mixed: sometimes the _Mr._ is separated from the name (as in the first 2 rows), other times not (as in the third row):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_sample.loc[book_sample['text'].str.contains('Mr. Dashwood'), view_columns].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason the results for _Mrs._ with NER appear even worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_sample.loc[book_sample['text'].str.contains('Mrs. March'), view_columns].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally __spaCy__ ([spacy.io, 2022](https://spacy.io/usage/rule-based-matching)) has a suggested workaround for this issue using rule-based matching, but I am limiting my exploration to the standard functionality in the interests of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Place names\n",
    "\n",
    "So far the quality of the names extracted by the proper nouns method is looking the best and at this point I'm planning to rely quite heavily (although not exclusively) on them. However, as I mentioned in the introduction, these names will include proper nouns that we do not want, with the most likely high-frequency ones being place names. We know __Great Expectations__ is very much to do with _London_ and a quick check shows us that _London_ is indeed being picked up by the proper nouns method, so we'll certainly need to reduce this problem as much as possible by identifying known place names and removing them from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_sample.loc[book_sample['text'].str.contains('London'), view_columns].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In __WordNet__ the most common 'sense' of a word is the first synset - or 'synonym set' ([Jurafsky & Martin, 2021](https://web.stanford.edu/~jurafsky/slp3/18.pdf)). So if the word _London_ is most typically associated with being a place name then this will be the first sense. Synsets are located within a hierarchy and place names resolve upwards in the hierarchy to the synset ```location.n.01'``` as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset = wn.synsets('London')\n",
    "synset[0].hypernym_paths()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this logic we can get an evaluation from __WordNet__ on whether a name is known to be a place or not. Let's look at 2 of the place names seen above (_London_ and _Cheapside_) as well as a character name _Pip_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location_names = ['London', 'Pip', 'Cheapside']\n",
    "for name in test_location_names:\n",
    "    if len(wn.synsets(name)) == 0:\n",
    "        location = 'not found in WordNet'\n",
    "    else:\n",
    "        location = wn.synset('location.n.01') in wn.synsets(name)[0].hypernym_paths()[0]\n",
    "    print(f'''{name}: place name = {location}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that __WordNet__ is probably only going to eliminate major place names for us. Although _Cheapside_ is a place, it's not one that is contained in __WordNet__.\n",
    "\n",
    "An alternative to __WordNet__ would be to use a set of __gazetteers__. A gazetteer is a dictionary of place names. For example _Cheapside_ is known to the __Gazetteer of British Place Names__ ([The Association of British Counties, 2022](https://gazetteer.org.uk/purchase)). This route would likely lead to better elimination of place names. But the drawback would be the need to compile multiple gazetteers for different countries (this one won't help us with __Little Women__ which is set in America), and this is probably a small project on its own so for now I will stick with __WordNet__ to eliminate the main ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Extract named entities / proper nouns from the full books\n",
    "\n",
    "Having refined our process a little, using a sample of the data, we are now ready to begin processing on the full books. Our first steps are:\n",
    "\n",
    "1. performing required punctuation replacements on the full texts\n",
    "2. extracting __nltk__ and __spaCy__ named entities for ```PERSON```\n",
    "3. extracting all proper nouns ```NNP```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of our data to continue processing\n",
    "book_entities = book_components.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_replacements = {'“':'\"', '”':'\"', '‘':\"'\", '’':\"'\" }\n",
    "for before, after in punctuation_replacements.items():\n",
    "    book_entities['text'] = book_entities['text'].str.replace(before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a little longer to run on the full books!\n",
    "book_entities['nltk_entities'] = book_entities['text'].progress_apply(lambda x: get_named_entities_nltk(x))\n",
    "book_entities['spacy_entities'] = book_entities['text'].progress_apply(lambda x: get_named_entities_spacy(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_entities['proper_nouns'] = book_entities['text'].progress_apply(lambda x: get_proper_nouns_nltk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now check the outputs are as expected\n",
    "book_entities.head(2).style.apply(highlight_column, subset=['nltk_entities', 'spacy_entities', 'proper_nouns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Get name frequencies and trim the list of names\n",
    "\n",
    "The next task is to compile a list of all the names identified, and then for each name count how many mentions were found by each of the 3 methods.\n",
    "\n",
    "In addition we'll perform some further 'cleanup' steps identified earlier:\n",
    "\n",
    "1. removing locations as far as possible (using __WordNet__)\n",
    "2. general cleanup steps:\n",
    "    * removing names that only consist of a title like _Mr._ or _Mrs_.\n",
    "    * removing names that only consist of a single character\n",
    "    * removing names that contain no alphanumeric characters\n",
    "    \n",
    "We then need to trim the number of names to a manageable size. For this I will employ 2 methods:\n",
    "\n",
    "* The first cut will be based on a threshold for the number of mentions for each name\n",
    "* The second cut will be based on a threshold for the % 'mention space' each name occupies\n",
    "\n",
    "The latter idea is based on Sack's findings ([2011](https://www.aaai.org/ocs/index.php/FSS/FSS11/paper/viewFile/4230/4528)) that character mentions follow a long tail distribution _and_ in addition I'm expecting that the method would also clear out more noise from the dataset.\n",
    "\n",
    "Counting name frequencies obviously needs to be done per book so my first step is to split our data into 3 separate dataframes: one for each book. I'll use a ```dict``` to hold this information to simplify further processing across all three books (where I can loop through the books to apply the same processing steps whenever I need):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_books = {}\n",
    "for author in authors:\n",
    "    processed_books[author] = book_entities[book_entities['author'] == author]\n",
    "    \n",
    "# Check the output is as expected\n",
    "processed_books['dickens'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get character frequencies - ```get_occcurences()```\n",
    "My next step is to retrieve the names that each technique has found and get a count of the frequencies of each. The following helper function will facilitate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurrences(pd_series, tuples = True):\n",
    "    '''Takes in a pandas series of names and returns a frequency count of names, tuples is True\n",
    "    for ner but should be False for proper nouns'''\n",
    "    combined = list(itertools.chain.from_iterable(pd_series[~pd_series.isna()]))\n",
    "    if tuples:\n",
    "        person_occurrences = [person[1] for person in combined]\n",
    "    else:\n",
    "        person_occurrences = [person for person in combined]\n",
    "    person_set = set(person_occurrences)\n",
    "    named_entity_counts = {word:person_occurrences.count(word) for word in person_set}\n",
    "    sorted_occurrences = {k: v for k, v in sorted(named_entity_counts.items(), \\\n",
    "                                                  reverse=True, key=lambda item: item[1])}\n",
    "    return sorted_occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile character frequencies - ```compile_entities()```\n",
    "\n",
    "Here we get occurrences per author and extraction type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_entities(book_dict, author, extraction_type):\n",
    "    series = book_dict[author][extraction_type].copy()\n",
    "    if extraction_type in ['nltk_entities', 'spacy_entities']:\n",
    "        tuples = True\n",
    "    else:\n",
    "        tuples = False\n",
    "    result = pd.json_normalize(get_occurrences(series, tuples = tuples)).transpose().reset_index()\n",
    "    result.columns = ['name', extraction_type]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_types = ['nltk_entities', 'spacy_entities', 'proper_nouns']\n",
    "entities = {}\n",
    "for author in authors:\n",
    "    entities[author] = {}\n",
    "    for extraction_type in extraction_types:\n",
    "        entities[author][extraction_type] = compile_entities(processed_books, \\\n",
    "                                                             author=author, extraction_type=extraction_type)\n",
    "        \n",
    "# Check the output is as expected\n",
    "entities['dickens']['nltk_entities'].head(5).style.apply(highlight_column, subset=['nltk_entities'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine entity counts - ```combine_entities()```\n",
    "\n",
    "And finally we combine the data so that we can compare the results (names found by all 3 methods, and the frequency of each by method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_entities(entity_dict, author, extraction_types):\n",
    "    # Create a list to hold character names\n",
    "    all_names = []\n",
    "    # Collect the character names generated by all 3 methods\n",
    "    for extraction_type in extraction_types:\n",
    "        all_names.extend(entity_dict[author][extraction_type]['name'].tolist())\n",
    "    # Dedupe character names\n",
    "    all_names = list(set(all_names)) \n",
    "    # Create a dataframe to hold our data\n",
    "    name_summary = pd.DataFrame(data=all_names, columns = ['name'])\n",
    "    # Bring in the frequencies for each method\n",
    "    for extraction_type in extraction_types:\n",
    "        name_summary = name_summary.merge(entity_dict[author][extraction_type], how='left', on='name')\n",
    "    # Fill 0 where a method found no occurrences for a name\n",
    "    name_summary.fillna(0, inplace=True)\n",
    "    name_summary = name_summary.astype('int64', errors='ignore')\n",
    "    return name_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    entities[author]['extraction_summary'] = combine_entities\\\n",
    "    (entities, author=author, extraction_types=extraction_types)\n",
    "\n",
    "# Check the output is as expected\n",
    "entities['dickens']['extraction_summary'].query('name == \"Joe\"').style.apply\\\n",
    "(highlight_column, subset=['nltk_entities', 'spacy_entities', 'proper_nouns']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the list of names based on number of mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results we can confirm 2 things:\n",
    "\n",
    "* The names found do indeed follow the expected long-tailed distribution in all 3 cases\n",
    "* The tails are ridiculously long - ```alcott``` has more than 1200 proper nouns!\n",
    "\n",
    "Given the goal of providing background information that can aid in literary analysis it's unnecessary to burden anyone with that many names! Furthermore a lot of those low-frequency names are probably just 'noise' as a result of the proper nouns including non-character information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    print(f'''{author}: {len(entities[author]['extraction_summary']['proper_nouns'])} names found''')\n",
    "    ax = entities[author]['extraction_summary']['proper_nouns'].sort_values\\\n",
    "        (ascending = False).reset_index(drop=True).plot(color = author_colors[author], linewidth=4, figsize = (20, 3))\n",
    "    plt.title(f'''{author} number of proper nouns found / frequencies''', fontsize = 16)\n",
    "    plt.ylabel('frequencies')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see how much noise is included in this raw dataset just by sampling some names. The objective is to eliminate very low frequency names either because they are noise (not actually character names) or because they are characters whose role is presumably very minor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['alcott']['extraction_summary'].sample(5, random_state=2).style.apply(highlight_column, subset=['name'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce entities based on count thresholds - ```reduce_entities()```\n",
    "\n",
    "Since the proper noun extraction appeared to produce the best _quality_ names I decided to only look at names where proper noun extraction found at least one instance - and in combination with this the name had to be found at least 3 times by any one of the extraction methods. Arriving at these cutoffs took a bit of offline experimentation and was something of a manual process given that we don't have a labelled dataset, but in the end these criteria work reasonably well for all 3 books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_entities(entity_dict, author):\n",
    "    reduced_entities = \\\n",
    "        entity_dict[author]['extraction_summary'][((entity_dict[author]['extraction_summary']['nltk_entities'] > 2 ) | \n",
    "        (entity_dict[author]['extraction_summary']['spacy_entities'] > 2) |\n",
    "        (entity_dict[author]['extraction_summary']['proper_nouns'] > 2)) & \n",
    "        (entity_dict[author]['extraction_summary']['proper_nouns'] != 0)].copy()\n",
    "    return reduced_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all entities / proper nouns with > 2 mentions\n",
    "main_entities = {}\n",
    "for author in authors:\n",
    "    main_entities[author] = reduce_entities(entities, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the names have been reduced to a much more manageable number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    print(f'''{author}: {len(main_entities[author]['proper_nouns'])} names found''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminate WordNet locations - ```test_for_location()```\n",
    "\n",
    "We can now test if a name is found as a WordNet location, and if so we drop it from the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_location(name):\n",
    "    '''Takes in a name and uses Wordnet to check if the most common sense (which is always the first one)\n",
    "    resolves to the hypernym 'location.n.01'.'''\n",
    "    synset = wn.synsets(name)\n",
    "    # The name may not occur in Wordnet (most person names don't)\n",
    "    if len(synset) == 0:\n",
    "        location = False\n",
    "    # But if it does, check if it could occur as a location\n",
    "    else:\n",
    "        location = wn.synset('location.n.01') in synset[0].hypernym_paths()[0]\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    main_entities[author]['location'] = main_entities[author]['name'].apply(lambda x: test_for_location(x))\n",
    "    to_drop = main_entities[author][main_entities[author]['location']==True].index\n",
    "    main_entities[author].drop(to_drop, inplace = True)\n",
    "    main_entities[author].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General cleanup steps - ```cleanup_entities()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_titles = ['Mr.', 'Mr', 'Mrs.', 'Mrs', 'Ms.', 'Ms', 'Miss', \n",
    "                 'Dr.', 'Dr', 'Rev.', 'Rev', 'Prof.', 'Prof']\n",
    "def cleanup_entities(entity_dict, author, common_titles=common_titles):\n",
    "    to_drop = []\n",
    "    # Get names that are just common titles\n",
    "    to_drop.extend(entity_dict[author][entity_dict[author]['name'].isin(common_titles)].index.tolist())\n",
    "    # Get names that are only 1 character long\n",
    "    to_drop.extend(entity_dict[author][entity_dict[author]['name'].str.len() == 1].index.tolist())\n",
    "    # Get names that contain no alpha characters\n",
    "    to_drop.extend(entity_dict[author][entity_dict[author]['name'].str.contains\\\n",
    "                                       (r'^[^a-zA-Z]*$', regex = True)].index.tolist())\n",
    "    cleaned_entity_dict = entity_dict[author].copy()\n",
    "    cleaned_entity_dict.drop(to_drop, inplace = True)\n",
    "    cleaned_entity_dict.reset_index(drop=True)  \n",
    "    return cleaned_entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    main_entities[author] = cleanup_entities(main_entities, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the number of names has been slightly reduced in all cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    print(f'''{author}: {len(main_entities[author]['proper_nouns'])} names found''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce entities based on % mentions - ```final_cut_entities()```\n",
    "\n",
    "In order to get a feel for how much 'space' a character takes up Sack ([2011](https://www.aaai.org/ocs/index.php/FSS/FSS11/paper/viewFile/4230/4528) citing Alex Woloch) , I looked at the mentions of each character as a % of the total mentions in our current list of names. Using a threshold of 0.1% (0.001 - again some iterations with manual review were required given the unlabelled dataset), I eliminated characters whose mention count was below this threshold as 'probably too minor to care about'. This step approximately halved the number of characters in ```dickens``` and ```alcott``` while leaving ```carroll``` as-is (the latter has much fewer minor characters compared to the other books). Our final frequency distributions are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_cut_entities(entity_dict, author):\n",
    "    final_cut_entity_dict = entity_dict[author].copy()\n",
    "    total_mentions = final_cut_entity_dict['proper_nouns'].sum()\n",
    "    final_cut_entity_dict['proper_nouns_perc'] = final_cut_entity_dict['proper_nouns'].apply\\\n",
    "        (lambda x: round(x/total_mentions, 4))\n",
    "    result = final_cut_entity_dict.query('proper_nouns_perc >= 0.001')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_entities = {}\n",
    "for author in authors:\n",
    "    reduced_entities[author] = final_cut_entities(main_entities, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with entities that have a percentage of proper nouns >= 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_entities['dickens'].head().style.apply(highlight_column, subset=['proper_nouns_perc'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    print(f'''{author}: {len(reduced_entities[author]['proper_nouns'])} names found''')\n",
    "    ax = reduced_entities[author]['proper_nouns'].sort_values(ascending = False).reset_index\\\n",
    "        (drop=True).plot(color = author_colors[author], linewidth=4, figsize = (20, 3))\n",
    "    plt.title(f'''{author} number of names / frequencies''', fontsize = 16)\n",
    "    plt.ylabel('frequencies')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Group similar names\n",
    "\n",
    "The next objective is to relate a list of names like the following with a single common grouping 'index':\n",
    "\n",
    "```['Herbert', 'Pocket', 'Herbert Pocket', 'Mrs. Pocket', 'Mr. Pocket', 'Mr. Matthew Pocket', 'Miss Sarah Pocket', 'Mr. Herbert', 'Sarah Pocket', 'Miss Pocket', 'Matthew Pocket']``` \n",
    "\n",
    "We can infer these are all related to one another in some way (although we cannot be sure how) as they share a similar group of individual names including 'Herbert', 'Pocket', 'Sarah', 'Matthew'.\n",
    "\n",
    "This may seem slightly counter-intuitive BUT it is the most pragmatic way I can think of to deal with similar names. For instance if we read _Herbert_ we would easily say that _Herbert Pocket_ should be the same fellow. But what about when we come across _Mr. Pocket_? Once we know of the existence of _Matthew Pocket_ we can no longer be sure which man is being referred to with _Mr. Pocket_. To err on the side of caution my approach is to 'lasso' all names which could be related to one another into a single group.\n",
    "\n",
    "With a small number of alternatives like this, we can then say they are aliases for the same character:\n",
    "\n",
    "```['Cat', 'Cheshire Cat']``` \n",
    "\n",
    "The moment there are too many as above, then we err on the side of caution and just pick out the name with the single largest frequency as a character name we can be sure of, and leave the rest to one side as 'uncertain'.\n",
    "\n",
    "The overall recipe for this section is:\n",
    "\n",
    "1. Generate a set of name permutations so that we can check which single names are contained within multi-word names, like 'Herbert' contained within 'Herbert Pocket'\n",
    "2. Where a set of names associated with a single word like 'Herbert', e.g. {'Herbert', 'Pocket'} overlaps with another set of names with a common element - say {'Sarah', 'Pocket'} - merge these names into a single group\n",
    "\n",
    "[Given a little more time to experiment it would have been useful to see how we could refine this based on the conventions of first name (usually unique) and surname (often not unique).]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group overlapping entities - ```group_entities()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for single names contained within multi-word names, and then group names with common elements\n",
    "# We don't want to group names on their generic components like 'Mr.' or 'of'\n",
    "name_stopwords = common_titles + ['of', 'Of', 'the' 'The']\n",
    "\n",
    "def group_entities(entity_dict, author):\n",
    "    # Get main list of names to test, e.g. 'Herbert Pocket'\n",
    "    names_to_test = entity_dict[author]['name'].tolist()\n",
    "    # Add single name components to this list e.g. 'Herbert', 'Pocket'\n",
    "    names_to_test = names_to_test + list(set([item for sublist in [name.split(' ') \\\n",
    "                                   for name in names_to_test] for item in sublist if item not in name_stopwords]))\n",
    "    # Generate name permutations\n",
    "    permutations = list(itertools.permutations(names_to_test, r=2))\n",
    "\n",
    "    relationships = []\n",
    "    # Get the multi-name relationships\n",
    "    for i in range(len(permutations)):\n",
    "        test_case = permutations[i]\n",
    "        if len(test_case[0].split(' ')) == 1:\n",
    "            if re.search(rf'\\b{test_case[0]}\\b', test_case[1]):\n",
    "                relationships.append(test_case)\n",
    "    # Add the single name relationships\n",
    "    single_names = [(name, name) for name in names_to_test]\n",
    "    for name in single_names:\n",
    "        if name not in relationships:\n",
    "            relationships.append(name)\n",
    "    # Group relationships by single names and their elements\n",
    "    d = defaultdict(list)\n",
    "    for key, value in relationships:\n",
    "        d[key].append(value)\n",
    "    d = dict(d)\n",
    "    \n",
    "    # Use 'successive merging' to build final name sets - method with thanks to Alain T. via this post:\n",
    "    # https://stackoverflow.com/questions/56567089/combining-lists-with-overlapping-elements\n",
    "    # - this uses sets and therefore intersection to check for overlapping elements (T., 2019)\n",
    "    pooled = [set(subList) for subList in d.values()]\n",
    "    merging = True\n",
    "    while merging:\n",
    "        merging=False\n",
    "        for i,group in enumerate(pooled):\n",
    "            merged = next((g for g in pooled[i+1:] if g.intersection(group)),None)\n",
    "            if not merged: continue\n",
    "            group.update(merged)\n",
    "            pooled.remove(merged)\n",
    "            merging = True\n",
    "    pooled = [list(name_set) for name_set in pooled]\n",
    "    names_df = pd.DataFrame(columns = ['name'])\n",
    "    names_df['name'] = pooled\n",
    "    names_df = names_df.explode('name')\n",
    "    names_df.reset_index(inplace=True)\n",
    "    \n",
    "    merged_df = entity_dict[author].copy()\n",
    "    merged_df = merged_df.merge(names_df, how = 'left', on = 'name')\n",
    "    \n",
    "    # Get total character mentions per index\n",
    "    totals = pd.DataFrame(merged_df.groupby(by = ['index'])['proper_nouns'].sum())\n",
    "    totals.reset_index(inplace = True)\n",
    "\n",
    "    # Get character counts per index\n",
    "    counts = pd.DataFrame(merged_df.groupby(by = ['index'])['name'].count())\n",
    "    counts.reset_index(inplace = True)\n",
    "    counts.columns = ['index', 'char_count']\n",
    "    \n",
    "    # Merge character totals and counts into final entities\n",
    "    merged_df = merged_df.merge(totals, how = 'left', on = 'index', suffixes = ('_ind_totals', '_grp_totals'))\n",
    "    merged_df = merged_df.merge(counts, how = 'left', on = 'index', )\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_entities = {}\n",
    "for author in authors:\n",
    "    merged_entities[author] = group_entities(reduced_entities, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that all the names containing _Pocket_ now share the same index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_entities['dickens'][merged_entities['dickens']['name'].str.contains\\\n",
    "                           ('Pocket')].style.apply(highlight_column, subset=['name', 'index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also all the names associated with, but not necessarily containing, _Pocket_ also share the same index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_view = merged_entities['dickens'][merged_entities['dickens']['name'].str.contains\\\n",
    "                                           ('Pocket')].iloc[0]['index']\n",
    "merged_entities['dickens'][merged_entities['dickens']['index'] == index_to_view].style.apply\\\n",
    "    (highlight_column, subset=['name', 'index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract final entities - ```extract_final_entities()```\n",
    "\n",
    "Our final step is to get the name per grouping that has the most mentions, we'll treat this as they 'key value' for the indices we've established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_entities(entity_dict, author):\n",
    "    final_entities = entity_dict[author].copy()\n",
    "    # Get the maximum per index for each character grouping based on proper_nouns_ind_totals\n",
    "    max_records = final_entities.groupby('index', group_keys=False).apply\\\n",
    "        (lambda x: x.loc[x['proper_nouns_ind_totals'].idxmax()])\n",
    "    # Get the records where we can only keep one name as there may be ambiguities (> 3 'variants')\n",
    "    singletons = max_records[max_records['char_count'] > 3].reset_index(drop=True)\n",
    "    # Drop these ambiguous records from our main df\n",
    "    to_drop = final_entities[final_entities['index'].isin(singletons['index'])].index\n",
    "    final_entities.drop(to_drop, inplace = True)\n",
    "    # And just re-include the singleton records we can be more sure about\n",
    "    final_entities = pd.concat([final_entities, singletons])\n",
    "    # Merge final_entities with max_records to get the single names representative of name variants\n",
    "    max_records.reset_index(drop = True, inplace = True)\n",
    "    final_entities = final_entities.merge(max_records[['index', 'name']], \\\n",
    "                                          how = 'left', on='index', suffixes=('_original', '_key'))\n",
    "    final_entities.rename(columns={'name_original':'name', 'name_key': 'key'}, inplace=True)\n",
    "    return final_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_entities = {}\n",
    "for author in authors:\n",
    "    final_entities[author] = extract_final_entities(merged_entities, author)\n",
    "\n",
    "# Check that the outputs are as expected\n",
    "final_entities['dickens'][final_entities['dickens']['name'].str.contains\\\n",
    "                          ('Herbert|Pocket|Pip')].style.apply(highlight_column, subset=['name', 'index', 'key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we are seeing that where we have name variants we can say are associated with reasonable certainty (< 3 variants) they have been retained and are grouped with a common index: see _Pip_. However, where there were name variants that we could not say for sure what the associations were only the single instance with the most mentions has been retained: see _Herbert_ which has been selected from amongst all the _Pocket_ names. \n",
    "\n",
    "\\[If I were to refine this method a little more I would look at possible first name / last name associations to see if genuinely related names could be extracted in slightly more detail, but that is again outside of the scope of this particular investigation.\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Save key information to our database\n",
    "\n",
    "### 3.8.1 Save ```book_entities```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_entities_sql = book_entities.copy()\n",
    "# Get the book entities into a format where we can save it to the DB (which does not like lists or tuples)\n",
    "book_entities_sql['nltk_entities'] = book_entities_sql['nltk_entities'].apply\\\n",
    "    (lambda x: ';'.join(map(str, x)) if x != None else 'None')\n",
    "book_entities_sql['spacy_entities'] = book_entities_sql['spacy_entities'].apply\\\n",
    "    (lambda x: ';'.join(map(str, x)) if x != None else 'None')\n",
    "book_entities_sql['lemmas'] = book_entities_sql['lemmas'].apply\\\n",
    "    (lambda x: ';'.join(x) if x != None else 'None')\n",
    "book_entities_sql['proper_nouns'] = book_entities_sql['proper_nouns'].apply\\\n",
    "    (lambda x: ';'.join(x) if x != None else 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can always convert back again with the following recipes:\n",
    "\n",
    "# For NER (which has tuples)\n",
    "# book_entities_sql['nltk_entities'].apply(lambda x: [tuple(re.sub(r'[\\(\\)\\']', '', item).split(', ')) \\\n",
    "# for item in x.split(';')] if x != 'None' else None)\n",
    "\n",
    "# For proper nouns (which has lists)\n",
    "# book_entities_sql['proper_nouns'].apply(lambda x: x.split(';') if x != 'None' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the outputs to our db\n",
    "book_entities_sql.to_sql('book_entities', connection, schema=None, \n",
    "              if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2 Save ```final_entities```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the database\n",
    "for author in authors:\n",
    "    table_name = author + '_entities'\n",
    "    final_entities[author].to_sql(table_name, connection, schema=None, \n",
    "              if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And check that it landed safely\n",
    "%sql SELECT name FROM sqlite_master WHERE type='table';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Evaluation\n",
    "\n",
    "### 3.9.1 Loop in our 4th unseen book ```bronte```\n",
    "\n",
    "The final 'recipe' was developed and refined on ```dickens```, ```carroll``` and ```alcott```. Before we evaluate I'm now going to add ```bronte``` so that we can evaluate the final results not only on the books used in the development process but on one that hasn't been seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bronte from our db\n",
    "processed_books['bronte'] = pd.read_sql_query\\\n",
    "    ('SELECT * FROM book_components WHERE author IN (\"bronte\")', 'sqlite:///book_store.db')\n",
    "processed_books['bronte']['lemmas'] = processed_books['bronte']['lemmas'].apply(lambda x: x.split(';'))\n",
    "\n",
    "# Replace punctuation\n",
    "for before, after in punctuation_replacements.items():\n",
    "    processed_books['bronte']['text'] = processed_books['bronte']['text'].str.replace(before, after)\n",
    "    \n",
    "# Get named entities\n",
    "processed_books['bronte']['nltk_entities'] = processed_books['bronte']['text'].progress_apply\\\n",
    "    (lambda x: get_named_entities_nltk(x))\n",
    "processed_books['bronte']['spacy_entities'] = processed_books['bronte']['text'].progress_apply\\\n",
    "    (lambda x: get_named_entities_spacy(x))\n",
    "\n",
    "# Get proper nouns\n",
    "processed_books['bronte']['proper_nouns'] = processed_books['bronte']['text'].progress_apply\\\n",
    "    (lambda x: get_proper_nouns_nltk(x))\n",
    "\n",
    "# Get name frequencies and trim lists\n",
    "for author in ['bronte']:\n",
    "    # Compile entities\n",
    "    entities[author] = {}\n",
    "    for extraction_type in extraction_types:\n",
    "        entities[author][extraction_type] = compile_entities(processed_books, author=author, \\\n",
    "                                                             extraction_type=extraction_type)\n",
    "    # Combine entities \n",
    "    entities[author]['extraction_summary'] = combine_entities(entities, author=author, \\\n",
    "                                                              extraction_types=extraction_types)\n",
    "    # Reduce entities\n",
    "    main_entities[author] = reduce_entities(entities, author)\n",
    "    # Remove locations   \n",
    "    main_entities[author]['location'] = main_entities[author]['name'].apply(lambda x: test_for_location(x))\n",
    "    to_drop = main_entities[author][main_entities[author]['location']==True].index\n",
    "    main_entities[author].drop(to_drop, inplace = True)\n",
    "    main_entities[author].reset_index(drop=True, inplace=True)\n",
    "    # General cleanup    \n",
    "    main_entities[author] = cleanup_entities(main_entities, author)\n",
    "    # Final cut    \n",
    "    reduced_entities[author] = final_cut_entities(main_entities, author)\n",
    "    # Group entities\n",
    "    merged_entities[author] = group_entities(reduced_entities, author)  \n",
    "    # Extract final entities\n",
    "    final_entities[author] = extract_final_entities(merged_entities, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 Get Wikidata into the right format for lookup\n",
    "\n",
    "In this step I will transform our Wikidata list of characters such that each index represents a 'main name' for the character and aliases are associated with that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the wikdata characters from our database\n",
    "wikidata = pd.read_sql_query('SELECT * FROM wikidata WHERE property = \"characters\"', 'sqlite:///book_store.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the string format back to a list / tuple format\n",
    "wikidata['data'] = wikidata['data'].apply(lambda x: [(name, alias.split('|')) \\\n",
    "if '|' in alias else (name, alias) for name, alias in [tuple(item.split('^'))  \n",
    "if '^' in item else (item, 'None') for item in x.split(';')]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assemble the final Wikidata list so that ```index``` is the unique id for each character, ```key``` is the 'main' name assigned to the character and ```name``` is the list of all names associated with that character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_chars = {}\n",
    "for author in all_authors:\n",
    "    wiki_char_list = wikidata.query('author == @author  and property == \"characters\"')['data'].tolist()\n",
    "    wiki_char_df = pd.DataFrame(wiki_char_list[0], columns =['key', 'name'])\n",
    "    # We're keeping the index here as our unique character key\n",
    "    wiki_char_df.reset_index(inplace = True)\n",
    "    # Get the rows which have aliases\n",
    "    aliases_df = wiki_char_df[wiki_char_df['name'].notna()]\n",
    "    # Each name should be associated with itself as an alias for convenience when matching later\n",
    "    wiki_char_df['name'] = wiki_char_df['key']\n",
    "    # Group the main names and the aliases together\n",
    "    wiki_char_df = pd.concat([wiki_char_df, aliases_df])\n",
    "    wiki_char_df = wiki_char_df.explode('name')\n",
    "    wikidata_chars[author] = wiki_char_df.sort_values('index').reset_index(drop= True)\n",
    "    \n",
    "# Check that the output is as expected\n",
    "wikidata_chars['bronte'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one manual adjustment I'm going to make to this list: Wikidata lists a character _Alice's sister_, however this character is never actually named in the book and therefore I'm going to exclude it for purposes of our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = wikidata_chars['carroll'][wikidata_chars['carroll']['key'] == \"Alice's sister\"].index\n",
    "wikidata_chars['carroll'] = wikidata_chars['carroll'].drop(to_drop).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.3 Match names found\n",
    "\n",
    "In this step I match names found in Wikidata to names found in our final entities data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in all_authors:\n",
    "    keys_to_match = dict(zip(wikidata_chars[author]['name'], wikidata_chars[author]['key']))\n",
    "    final_entities[author]['wiki_terms_key'] = final_entities[author]['key'].apply\\\n",
    "        (lambda x: '; '.join(list(set([key for name, key in keys_to_match.items() if re.search\\\n",
    "                                       (rf'\\b{x}\\b', name) or re.search(rf'\\b{name}\\b', x)]))))\n",
    "    indices_to_match = dict(zip(wikidata_chars[author]['name'], wikidata_chars[author]['index']))\n",
    "    final_entities[author]['wiki_terms_index'] = final_entities[author]['key'].apply\\\n",
    "        (lambda x: '; '.join(list(set([str(index) for name, index in indices_to_match.items() \\\n",
    "                                       if re.search(rf'\\b{x}\\b', name) or re.search(rf'\\b{name}\\b', x)]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.4 Manual review of top 20 names and \"precision\"\n",
    "\n",
    "Remember that precision answers the question '_Of the results we got, how many were valid?_'. As mentioned previously, this is by necessity a manual exercise, since we do not have exhaustive character lists from Wikidata. I will be limiting the character visualizations in the next section to only the top 20 per novel, so I'm going to assess how many of these top 20 were valid results. Top 20 refers to the top 20 'indexes' found so _Pip_ and _Mr. Pip_ will count as one name.\n",
    "\n",
    "In evaluating if a name is valid or not, 2 aspects have to be considered - I have chosen to handle them as follows:\n",
    "\n",
    "* Was the name identified a valid character name? (if not -1 from score)\n",
    "* Was the name identified genuine, but not picked up as being an alias for another? (in this case -0.5 from score)\n",
    "\n",
    "The method of scoring is rather arbitrary - it should only be viewed as a rough guide to evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = ['name', 'key', 'index', 'proper_nouns_ind_totals', 'proper_nouns_grp_totals', 'wiki_terms_key', 'wiki_terms_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = {}\n",
    "for author in all_authors:\n",
    "    unique_indices_totals = final_entities[author][['index', 'proper_nouns_grp_totals']].drop_duplicates()\n",
    "    top_indices = unique_indices_totals.nlargest(20, 'proper_nouns_grp_totals')['index'].tolist()\n",
    "    top_20[author] = final_entities[author][final_entities[author]['index'].isin(top_indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dickens top 20\n",
    "\n",
    "By way of reminder: ```dickens``` had the smallest set of characters in Wikidata - below (check field ```wiki_terms_key```) we see which matches were found in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Number of unique Wikidata characters: {len(wikidata_chars['dickens']['key'].unique())}\n",
    "\n",
    "Wikidata character list excluding aliases: \n",
    "{wikidata_chars['dickens']['key'].unique().tolist()}\n",
    "''')\n",
    "top_20['dickens'][fields_of_interest].sort_values('index', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison to Wikidata\n",
    "\n",
    "Notice the following:\n",
    "\n",
    "* _Abel Magwitch_, although listed as a main character by WikiData, is not found in our top 20. This highlights 2 issues: 1) inability to match aliases: we have _Provis_ which is in fact an alias for _Magwitch_ but we have no way of knowing they are one and the same character and 2) some characters loom large, even if they are not frequently mentioned by name. In the beginning of __Great Expectations__ our hero _Pip_ has an encounter with _Magwitch_ which alters the course of his life, but in ways we really only understand later when _Magwitch_ returns to the narrative as _Provis_.\n",
    "* Notice also, the name _Drummle_ is associated only with _Estella Drummle_ in Wikidata so there is some confusion on the matching between our data and Wikidata in this instance. Availability of a more comprehensive character list in Wikidata would have helped to alleviate this evaluation issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision of dickens top 20\n",
    "\n",
    "* Most of the names in the top 20 are genuine names (even _Aged_ - there is actually a character referred to as _Aged P._ or _Aged Parent_ in the book!)\n",
    "* _Sunday_ is the only name that is incorrect (-1)\n",
    "* _Handel_ is one of Pip's nicknames (-0.5)\n",
    "\n",
    "\n",
    "Our manual precision calculation is therefore:\n",
    "\n",
    "$$ \\frac{TP}{TP + FP} = \\frac{18.5}{20} = 0.93$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carroll top 20\n",
    "\n",
    "By way of reminder: ```carroll``` had quite a few unusual characters - below we see which matches were found in our data - surprisingly comprehensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Number of unique Wikidata characters: {len(wikidata_chars['carroll']['key'].unique())}\n",
    "\n",
    "Wikidata character list excluding aliases: \n",
    "{wikidata_chars['carroll']['key'].unique().tolist()}\n",
    "''')\n",
    "top_20['carroll'][fields_of_interest].sort_values('index', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison to Wikidata\n",
    "\n",
    "The results are surprisingly good, with similar variants of names being correctly grouped - except where we could not be sure how to understand relationships. For example it's disappointing the _Queen_ does not also include the variant _Queen of Hearts_, but as discussed above, this is as a result of the similar name _Knave of Hearts_ confusing matters.\n",
    "\n",
    "Also (somewhat randomly!) _King_ has been extracted successfully as a separate character from the _Queen_ / _Queen of Hearts_ because in the book he is never referenced as _King of Hearts_ although that is what he is. Because of this no room for doubt was created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review of precision\n",
    "\n",
    "* Most of the names in the top 20 are genuine names \n",
    "* _Come_ is the only name that is shouldn't be in the list (-1)\n",
    "* _Majesty_, is ambiguous: does it refer to the King or the Queen or both? We can't know without context (-0.5)\n",
    "* _Footman_ is also ambiguous, there are in fact 2 footmen, the _Frog-Footman_ and the _Fish-Footman_ (-0.5)\n",
    "\n",
    "\n",
    "\n",
    "Our manual precision calculation is therefore:\n",
    "\n",
    "$$ \\frac{TP}{TP + FP} = \\frac{18}{20} = 0.90$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alcott top 20\n",
    "\n",
    "By way of reminder: ```alcott``` was essentially about the _March_ family so everyone could have the surname _March_. Wikidata had an extremely comprehensive character list compared with Dickens. Below we see which matches were found in our data - where ```wiki_terms_index``` contains more than one item we cannot be sure if the character is a match or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Number of unique Wikidata characters: {len(wikidata_chars['alcott']['key'].unique())}\n",
    "\n",
    "Wikidata character list excluding aliases: \n",
    "{wikidata_chars['alcott']['key'].unique().tolist()}\n",
    "''')\n",
    "top_20['alcott'][fields_of_interest].sort_values('index', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review of precision\n",
    "\n",
    "* Most of the names in the top 20 are genuine names (_May_ is a real character not a month!)\n",
    "* _Christmas_ and _Poor_ are the only names that shouldn't be in the list (-2)\n",
    "* _Teddy_ and _Laurie_ are ambiguous - they are one and the same person (2 x -0.5)\n",
    "* _Mrs. March_, _Mother_, _Marmee_ are ambiguous - they are one and the same person (3 x -0.5)\n",
    "\n",
    "\n",
    "Our manual precision calculation is therefore:\n",
    "\n",
    "$$ \\frac{TP}{TP + FP} = \\frac{15.5}{20} = 0.78$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bronte top 20\n",
    "\n",
    "```bronte``` also has a small set of characters in Wikidata - below (check field ```wiki_terms_key```) we see which matches were found in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Number of unique Wikidata characters: {len(wikidata_chars['bronte']['key'].unique())}\n",
    "\n",
    "Wikidata character list excluding aliases: \n",
    "{wikidata_chars['bronte']['key'].unique().tolist()}\n",
    "''')\n",
    "top_20['bronte'][fields_of_interest].sort_values('index', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison to Wikidata\n",
    "\n",
    "There were only 3 characters listed on Wikidata - we got them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision of bronte top 20\n",
    "\n",
    "* Most of the names in the top 20 are genuine names (including _St. John_, pronounced 'sinjin' when it is someone's name)\n",
    "* _Did_, _Thornfield_ and _Lowood_ are the 3 names that are incorrect (-3)\n",
    "* _God_ is debatable (-0.5)\n",
    "\n",
    "\n",
    "Our manual precision calculation is therefore:\n",
    "\n",
    "$$ \\frac{TP}{TP + FP} = \\frac{16.5}{20} = 0.83$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.5 Recall\n",
    "\n",
    "I'm going to look at recall from 2 points of view:\n",
    "\n",
    "__1. Overall, of the results we should have obtained (Wikidata list), how many did we get?__\n",
    "\n",
    "Recall is influenced by the number of items that are in the Wikidata lists. __Great Expectations__ actually has many more characters, but only the 6 very _main_ ones were given, where with __Little Women__ 61 characters were given, many of whom really are quite minor.\n",
    "\n",
    "__2. In the Top 20, of the results we should have obtained (Wikidata list), how many did we get?__\n",
    "\n",
    "This latter is not really 'recall' but gives us an indication of how many of the characters we wanted to get actually turned up in the Top 20.\n",
    "\n",
    "Here I create and process a function to compile the results and store them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_recall_data(final_entities_dict):\n",
    "    recall_tracking = {}\n",
    "    for author in all_authors:\n",
    "        recall_tracking[author] = {}\n",
    "        wiki_items = wikidata_chars[author]['key'].unique().tolist()\n",
    "        found_items = final_entities_dict[author].loc[(final_entities_dict[author]['wiki_terms_key'] != '') & \\\n",
    "                     (~final_entities_dict[author]['wiki_terms_key'].str.contains(';')), \\\n",
    "                                                      'wiki_terms_key'].unique().tolist()\n",
    "        other_items = final_entities_dict[author].loc[~final_entities_dict[author]['wiki_terms_key'].isin\\\n",
    "                                                      (found_items), 'key'].unique().tolist()\n",
    "        recall_tracking[author]['wiki_items'] = len(wiki_items)\n",
    "        recall_tracking[author]['found'] = len(found_items)\n",
    "        recall_tracking[author]['not_found'] = len(list(set(wiki_items).difference(set(found_items))))\n",
    "        recall_tracking[author]['recall'] = len(found_items) / len(wiki_items)\n",
    "        recall_tracking[author]['found_items'] = found_items\n",
    "        recall_tracking[author]['not_found_items'] = list(set(wiki_items).difference(set(found_items)))\n",
    "        recall_tracking[author]['other_items'] = other_items\n",
    "    return recall_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_tracking = compile_recall_data(final_entities)\n",
    "top20_tracking = compile_recall_data(top_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.5.1 Overall results\n",
    "\n",
    "Below we see, of the results we should have obtained (Wikidata list), how many we got from the final list of characters (pie chart sizes are notionally relative to the number of characters that were listed in Wikidata):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart sizes are notionally relative to the number of characters that were listed in Wikidata:\n",
    "labels = ['found', 'not_found']\n",
    "relative_wikidata_sizes = {'dickens': (3,3), 'carroll': (4, 4), 'alcott': (5, 5), 'bronte': (3,3)}\n",
    "for author in all_authors:\n",
    "    data = [overall_tracking[author]['found'], overall_tracking[author]['not_found']]\n",
    "    fig1, ax = plt.subplots(figsize=relative_wikidata_sizes[author])\n",
    "\n",
    "    ax.pie(x=data, labels=labels, autopct='%1.1f%%',\n",
    "            shadow=True, startangle=90, colors = [author_colors[author], 'lightgrey'])\n",
    "    plt.title(f'''recall for {author} - {overall_tracking[author]['found']} / \\\n",
    "{len(wikidata_chars[author]['key'].unique())} names found from wikidata list''', fontsize = 16)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'''Found from Wikidata: \n",
    "    \n",
    "    {sorted(overall_tracking[author]['found_items'])}\n",
    "\n",
    "Not found from Wikidata:\n",
    "\n",
    "    {sorted(overall_tracking[author]['not_found_items'])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see above how imperfect the metric is, being heavily influenced by the level of detail available in WikiData. Notwithstanding, I'm satisfied with these results: even in the case of ```alcott```, to find 29 of the given 61 names is acceptable - especially given that the 29 contains all the characters that are usually top of mind for me as a human reader: _Jo_, _Meg_, _Amy_, _Beth_, _Laurie_, _Marmee_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.5.2 Top 20 results\n",
    "\n",
    "Below we see, of the results we should have obtained (Wikidata list), how many we got from in the Top 20 list of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart sizes are notionally relative to the number of characters that were listed in Wikidata:\n",
    "labels = ['in wikidata', 'not in wikidata']\n",
    "relative_wikidata_sizes = {'dickens': (3,3), 'carroll': (4, 4), 'alcott': (5, 5), 'bronte': (3,3)}\n",
    "for author in all_authors:\n",
    "    data = [top20_tracking[author]['found'], 20 - top20_tracking[author]['found']]\n",
    "    fig1, ax = plt.subplots(figsize=relative_wikidata_sizes[author])\n",
    "\n",
    "    ax.pie(x=data, labels=labels, autopct=lambda x: '{:.0f}'.format(x*np.sum(data)/100),\n",
    "            shadow=True, startangle=90, colors = [author_colors[author], 'lightgrey'])\n",
    "    plt.title(f'''{author} - {top20_tracking[author]['found']} names found from wikidata list in top 20 names''', \\\n",
    "              fontsize = 16)\n",
    "    plt.show()\n",
    "    print(f'''Found from Wikidata: \n",
    "    \n",
    "    {sorted(top20_tracking[author]['found_items'])}\n",
    "\n",
    "Not from Wikidata:\n",
    "\n",
    "    {sorted(top20_tracking[author]['other_items'])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the Top 20 detail above, there are a few names that are not valid characters in the set of names 'Not from Wikidata' but an overall majority of those in the grey pies are valid, even though not mentioned by Wikidata. \n",
    "\n",
    "### 3.9.6 BookNLP comparison\n",
    "\n",
    "At this point I would like branch off just to show the Top 20 results obtained via the [BookNLP demo](https://colab.research.google.com/drive/1c9nlqGRbJ-FUP2QJe49h21hB4kUXdU_k?usp=sharing) on Google Colab. I ran the big model to extract the top 20 characters.\n",
    "\n",
    "#### dickens\n",
    "\n",
    "```\n",
    "Id\tCount\tName\n",
    "302\t1244\tHerbert\n",
    "245\t1191\tMiss Havisham\n",
    "175\t1170\tJoe\n",
    "289\t974\t Wemmick\n",
    "214\t953\t Estella\n",
    "265\t839\t Mr. Jaggers\n",
    "269\t685\t Pip\n",
    "204\t602\t Biddy\n",
    "191\t410\t Mr. Pumblechook\n",
    "184\t348\t Mr. Wopsle\n",
    "315\t175\t Drummle\n",
    "403\t146\t Compeyson\n",
    "396\t132\t Provis\n",
    "304\t117\t Handel\n",
    "275\t115\t Trabb\n",
    "307\t115\t Mrs. Pocket\n",
    "247\t112\t Orlick\n",
    "392\t106\t Magwitch\n",
    "230\t97\t  Mr. Pocket\n",
    "226\t68\t  Camilla\n",
    "```\n",
    "\n",
    "_Observations_:\n",
    "\n",
    "* Aliases are also not picked up by BookNLP: _Provis_ and _Magwitch_ have separate character id's, as do _Pip_ and _Handel_, and we can't be sure about _Herbert_ and _Mr. Pocket_ either.\n",
    "\n",
    "#### carroll\n",
    "\n",
    "```\n",
    "Id\tCount\tName\n",
    "21\t691\t  Alice\n",
    "59\t79\t   Alice\n",
    "27\t50\t   the Mouse\n",
    "23\t35\t   the Rabbit\n",
    "45\t12\t   the Caterpillar\n",
    "51\t11\t   the Hatter\n",
    "53\t11\t   the Dormouse\n",
    "25\t8\t    Dinah\n",
    "37\t8\t    the Dodo\n",
    "52\t8\t    the March Hare\n",
    "42\t7\t    W. RABBIT\n",
    "48\t7\t    the Cheshire - Cat\n",
    "54\t7\t    the Knave of Hearts\n",
    "35\t5\t    the Duck\n",
    "43\t5\t    the Rabbit's--\"Pat ! Pat\n",
    "28\t4\t    William the Conqueror\n",
    "40\t4\t    The Duchess\n",
    "41\t4\t    Mary Ann\n",
    "46\t4\t    the Pigeon\n",
    "57\t4\t    Two\n",
    "```\n",
    "\n",
    "_Observations_:\n",
    "\n",
    "* There are some issues with the _White Rabbit_, and strangely _Alice_ is counted as 2 separate character id's\n",
    "\n",
    "#### alcott\n",
    "\n",
    "```\n",
    "Id\tCount\tName\n",
    "134\t6356\tJo\n",
    "192\t2627\tAmy\n",
    "163\t1766\tLaurie\n",
    "136\t1101\tLaurie\n",
    "223\t1065\tBeth\n",
    "200\t949\t Meg\n",
    "149\t702\t Mrs. March\n",
    "467\t467\t Mr. Bhaer\n",
    "199\t362\t John\n",
    "283\t300\t Laurie\n",
    "327\t238\t Mother\n",
    "153\t235\t Hannah\n",
    "558\t234\t Demi\n",
    "154\t208\t Aunt March\n",
    "239\t176\t Meg\n",
    "292\t144\t Fred\n",
    "448\t135\t Beth\n",
    "328\t95\t  Beth\n",
    "179\t93\t  Mr. March\n",
    "290\t82\t  Miss Kate\n",
    "```\n",
    "\n",
    "_Observations_:\n",
    "\n",
    "* Again we see some duplicated character names (for example 3 instances of _Beth_)\n",
    "\n",
    "#### bronte\n",
    "\n",
    "```\n",
    "Id\tCount\tName\n",
    "300\t1917\tMr. Rochester\n",
    "188\t1202\tSt. John\n",
    "155\t819\t Jane\n",
    "168\t449\t Bessie\n",
    "268\t443\t Adèle\n",
    "157\t342\t Mrs. Fairfax\n",
    "221\t341\t Helen\n",
    "308\t324\t Miss Ingram\n",
    "167\t281\t Mrs. Reed\n",
    "171\t240\t Georgiana\n",
    "242\t235\t Mary\n",
    "417\t201\t Diana\n",
    "209\t167\t Miss Temple\n",
    "306\t136\t Mrs. Fairfax\n",
    "204\t134\t Mr. Brocklehurst\n",
    "170\t129\t John\n",
    "271\t125\t Grace Poole\n",
    "349\t115\t Mason\n",
    "378\t109\t Jane\n",
    "163\t107\t Reader\n",
    "```\n",
    "\n",
    "_Observations_:\n",
    "\n",
    "* What we can see from the ```Count``` column in each case is that coreference resolution (which is part of the default pipeline) has increased the number of mentions per character considerably compared to my results.\n",
    "\n",
    "Overall, having seen that, even with the latest technology, this is quite a hard problem to solve, I'm not displeased with the results obtained using my relatively naïve techniques!\n",
    "\n",
    "In the final section I will reflect on some improvements that I believe could be made in future iterations. In the meantime I will proceed to the second part of this project: looking at some analyses and visualizations we could present to a human reader to complement their reading of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsm020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
